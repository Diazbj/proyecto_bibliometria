@inproceedings{10.1145/3675249.3675261,
author = {Gong, Lingyan and Deng, Huan},
title = {Impact of AI Technologies on Education Modernization in China: A Knowledge Graph Analysis},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675261},
doi = {10.1145/3675249.3675261},
abstract = {Artificial intelligence is playing an increasingly important role in the modernization of education in China. At present, the implementation and application of artificial intelligence technologies such as intelligent tutoring, virtual experiment and intelligent evaluation in educational scenes have brought about innovative changes in educational intellectualization, which has greatly promoted the development of Chinese path to modernization. On the basis of explaining the relationship between artificial intelligence and the modernization of education in China, this article searched 667 articles in Chinese core journals on "artificial intelligence" and "modernization of education" through CNKI. It was found that the number of articles published in domestic journals has shown a significant growth trend in recent years, with research mainly focused on the economically and culturally developed central and eastern regions of China, where university teachers have become the absolute mainstay of research in this field, Some university authors have established close collaborative publishing relationships. The education field attaches great importance to the educational application of artificial intelligence, and intelligent education has become a hot research field in teacher training universities. At the national level, the development of artificial intelligence in the modernization of education is also highly valued and supported, with fund support accounting for over 70\%. Starting from the inherent logic of artificial intelligence and the modernization of education in China, corresponding policy recommendations have been put forward to effectively promote the high-quality development of education modernization in China.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {64–74},
numpages = {11},
location = {Sanming, China},
series = {ICCMT '24}
}

@inproceedings{10.1145/3639474.3640062,
author = {Ouhbi, Sofia},
title = {Bridging the Theory-Practice Gap in a Maintenance Programming Course: An Experience Report},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640062},
doi = {10.1145/3639474.3640062},
abstract = {This paper presents our experience in teaching a maintenance programming course with the aim of bridging the gap between theory and practice, a recurring issue in previous course offerings. To achieve this goal, we implemented active learning strategies within an active learning classroom setting and redesigned the project work. Our approach involves peer learning and teamwork activities to cover various aspects of legacy code maintenance. For the project work, we adopted an open-ended approach that allowed students to choose their legacy code projects, which could be open-source software or a previous software project they had worked on. Analysis of students' feedback and project reports highlighted the effectiveness of our approach in bridging the gap between theory and practice. We believe that our approach had the potential to enhance students' engagement and critical thinking abilities, as well as improve practical maintenance skills relevant to their future careers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {359–367},
numpages = {9},
keywords = {software maintenance, software engineering education, open-ended project, group work, active learning, students engagement, generative AI},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3589335.3651935,
author = {Stanley Jothiraj, Fiona Victoria and Mashhadi, Afra},
title = {Phoenix: A Federated Generative Diffusion Model},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651935},
doi = {10.1145/3589335.3651935},
abstract = {Generative AI has made impressive strides in enabling users to create diverse and realistic visual content such as images, videos, and audio. However, training generative models on large centralized datasets can pose challenges in terms of data privacy, security, and accessibility. Federated learning (FL) is an approach that uses decentralized techniques to collaboratively train a shared deep learning model while retaining the training data on individual edge devices to preserve data privacy. This paper proposes a novel method for training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data sources using FL techniques. Diffusion models, a newly emerging generative model, show promising results in achieving superior quality images than Generative Adversarial Networks (GANs). Our proposed method Phoenix is an unconditional diffusion model that leverages strategies to improve the data diversity of generated samples even when trained on data with statistical heterogeneity or Non-IID (Non-Independent and Identically Distributed) data. We demonstrate how our approach outperforms the default diffusion model in a FL setting. These results indicate that high-quality samples can be generated by maintaining data diversity, preserving privacy, and reducing communication between data sources, offering exciting new possibilities in the field of generative AI.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1568–1577},
numpages = {10},
keywords = {diffusion models, federated learning, generative ai, heterogeneous data},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3706598.3713897,
author = {Kadoma, Kowe and Metaxa, Dana\'{e} and Naaman, Mor},
title = {Generative AI and Perceptual Harms: Who's Suspected of using LLMs?},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713897},
doi = {10.1145/3706598.3713897},
abstract = {Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools, they may risk causing a variety of harms, potentially disproportionately burdening historically marginalized groups. In this work, we introduce and evaluate perceptual harms, a term for the harms caused to users when others perceive or suspect them of using AI. We examined perceptual harms in three online experiments, each of which entailed participants evaluating write-ups from mock freelance writers. We asked participants to state whether they suspected the freelancers of using AI, to rank the quality of their writing, and to evaluate whether they should be hired. We found some support for perceptual harms against certain demographic groups. At the same time, perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {861},
numpages = {17},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3629606.3629635,
author = {Xue, Cheng and Gao, Yingting and Robin, Ananda and Du, Jiachen and Xu, Qianyao and Fu, Xinyi},
title = {Meta-Home: Smart Home Digital Twin Design from the Perspective of Smart metaverse},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629635},
doi = {10.1145/3629606.3629635},
abstract = {With the development of smart home technology and meta-verse technology, people tend to combine the two technologies to build a more appealing experience. In this context, the concept of Meta-Home (digital twin of smart home) has been proposed, however, there is little research related to the theoretical framework and design practice of Meta-Home. This article first introduces the design strategies on how to build Meta-Home from the theoretical level, then carries out design practices in a real smart home environment based on the theoretical framework, and evaluates through user experiments to explore the platform’s efficiency in appliance management and usage. The framework, practical experience, and research insights can provide inspiration and guidance for future researchers of the design of digital twin and smart home.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {309–320},
numpages = {12},
keywords = {Digital Twin, Metaverse, Smart Home},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@inproceedings{10.1145/3676151.3719368,
author = {Grillmeyer, Daniel and Hadry, Marius and Lesch, Veronika and Borst, Vanessa and Leppich, Robert and Bauer, Andr\'{e} and Kounev, Samuel},
title = {Quantifying Data Leakage in Failure Prediction Tasks},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719368},
doi = {10.1145/3676151.3719368},
abstract = {With the ever increasing importance of cloud computing and a strong focus on reliable data centers, a high amount of research has been done on failure prediction for hard disk drives. The collection of monitoring data, such as SMART statistics (Self-Monitoring, Analysis, and Reporting Technology) from operational HDDs, enables operators to obtain predictions about the expected remaining useful life. Numerous methods for HDD failure prediction have been published in recent years, and their evaluation has shown decent results. However, a naive splitting into training and test sets can lead to data leakage and, thus, over-optimistic results that cannot be achieved on the data of scientific interest. In this paper, we propose a novel data leakage measure for quantifying the amount of data leakage in training and test datasets. Further, we define four splitting techniques and evaluate our measure in terms of the performance optimism of classification models with respect to these different splitting strategies. Our results consistently show that splitting techniques prone to data leakage induce an overestimation of predictive performance. Overall, we were able to show the usefulness of the defined data leakage measure, as well as its connection with different splitting techniques and the performance optimism of prediction models.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {334–346},
numpages = {13},
keywords = {data leakage measure, data splitting, deep learning, hdd failure prediction, machine learning, performance optimism},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3706598.3713720,
author = {Rasch, Julian and T\"{o}ws, Julia and Hirzle, Teresa and M\"{u}ller, Florian and Schmitz, Martin},
title = {CreepyCoCreator? Investigating AI Representation Modes for 3D Object Co-Creation in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713720},
doi = {10.1145/3706598.3713720},
abstract = {Generative AI in Virtual Reality offers the potential for collaborative object-building, yet challenges remain in aligning AI contributions with user expectations. In particular, users often struggle to understand and collaborate with AI when its actions are not transparently represented. This paper thus explores the co-creative object-building process through a Wizard-of-Oz study, focusing on how AI can effectively convey its intent to users during object customization in Virtual Reality. Inspired by human-to-human collaboration, we focus on three representation modes: the presence of an embodied avatar, whether the AI’s contributions are visualized immediately or incrementally, and whether the areas modified are highlighted in advance. The findings provide insights into how these factors affect user perception and interaction with object-generating AI tools in Virtual Reality as well as satisfaction and ownership of the created objects. The results offer design implications for co-creative world-building systems, aiming to foster more effective and satisfying collaborations between humans and AI in Virtual Reality.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {144},
numpages = {14},
keywords = {Co-creative systems; Generative AI; 3D Creation; Virtual Reality; User Studies},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3626252.3630774,
author = {Minagar, Sepehr and Sakzad, Amin and Tack, Guido and Rudolph, Carsten and Sheard, Judithe},
title = {ALAN: Assessment-as-Learning Authentic Tasks for Networking},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630774},
doi = {10.1145/3626252.3630774},
abstract = {In this experience paper, we present ALAN, a framework to automate the generation of authentic assessment tasks in networking courses (NC). Using ALAN, all students in a cohort complete a set of assessment tasks generated from the same skeleton, with each student having their own parameters as input. The way we run ALAN assessments fosters students' self-regulation and peer learning and activates students' engagement in learning through assessment. We present three different ALAN assessments. We finally report on student perceptions and satisfaction and reflect on our experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {853–859},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, automation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627673.3679592,
author = {Oh, Sejoon and Verma, Gaurav and Kumar, Srijan},
title = {Adversarial Text Rewriting for Text-aware Recommender Systems},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679592},
doi = {10.1145/3627673.3679592},
abstract = {Text-aware recommender systems incorporate rich textual features, such as titles and descriptions, to generate item recommendations for users. The use of textual features helps mitigate cold-start problems, and thus, such recommender systems have attracted increased attention. However, we argue that the dependency on item descriptions makes the recommender system vulnerable to manipulation by adversarial sellers on e-commerce platforms. In this paper, we explore the possibility of such manipulation by proposing a new text rewriting framework to attack text-aware recommender systems. We show that the rewriting attack can be exploited by sellers to unfairly uprank their products, even though the adversarially rewritten descriptions are perceived as realistic by human evaluators. Methodologically, we investigate two different variations to carry out text rewriting attacks: (1) two-phase fine-tuning for greater attack performance, and (2) in-context learning for higher text rewriting quality. Experiments spanning 3 different datasets and 4 existing approaches demonstrate that recommender systems exhibit vulnerability against the proposed text rewriting attack. Our work adds to the existing literature around the robustness of recommender systems, while highlighting a new dimension of vulnerability in the age of large-scale automated text generation.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1804–1814},
numpages = {11},
keywords = {automated text generation, large language models, model robustness, text rewriting attack, text-aware recommender systems},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inbook{10.1145/3676641.3716245,
author = {Jeong, Jinwoo and Ahn, Jeongseob},
title = {Accelerating LLM Serving for Multi-turn Dialogues with Efficient Resource Management},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716245},
abstract = {Although there have been significant efforts to make LLM serving efficient, we observe two limitations of current state-of-the-art serving frameworks in handling multi-turn dialogues between users and assistants, particularly in chat scenarios. First, existing LLM frameworks incur substantial computational overhead in recomputing attention keys and values (KVs) for understanding context across multiple turns of user queries. Second, as the prompt length of user queries is amplified due to multi-turns, a first-come-first-served (FCFS) scheduling policy often causes head-of-line blocking issues, leading to underutilization of GPU resources.To address these limitations, we present FlashGen to rapidly complete multi-turn queries by efficiently utilizing the compute and memory resources of GPUs as well as the host hardware (e.g., DRAM and SSD). We introduce a multi-level KV cache comprised of GPU, CPU, and SSD, to efficiently retain attention KVs from prior turns. Our approach employs low-cost cache restoration techniques to avoid the recomputation burden. Further, we propose a request reordering technique to effectively utilize GPU memory. This scheduling technique carefully adjusts the request order without compromising fairness. Our proposed techniques outperform the vLLM framework in terms of both latency and throughput. For OPT 30B and Llama-2 70B models with the ShareGPT dataset, we achieve 1.63x and 2.85x better throughput, respectively while in a similar latency boundary.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3670653.3670669,
author = {Beier, Roman and Wolling, Florian and Hornecker, Eva and Michahelles, Florian},
title = {TipTopTyping: A Thumb-to-Finger Text Input Method and Character Layout Optimized for Mobile Spatial Computing},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3670669},
doi = {10.1145/3670653.3670669},
abstract = {While text input remains the primary interaction method with most computer applications, it faces diverse challenges with spatial computing devices becoming successively more wearable and mobile. We present TipTopTyping, a novel computer vision-based thumb-to-finger text input method for virtual and augmented reality that uses pinch gestures between thumb and fingertips for easy and more intuitive text entry. With OPTI, we further propose a new character layout specifically designed and optimized for this input modality. The system performance is evaluated in a user study (N = 20) of two mobile scenarios: standing and walking. After only 12 sentences of practice, the participants quickly achieved mean text entry rates of 6.15 and 5.69 words per minute and mean accuracies of 1.27 and 1.43 keystrokes per character while standing and walking, respectively. Furthermore, OPTI not only shows a 4.36 ,\% better typing accuracy but also the potential to outperform QWERTY layouts in writing speed with a little more practice.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {196–206},
numpages = {11},
keywords = {mobile text input, optimized character layout, spatial computing, thumb-to-finger pinches},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3706598.3713246,
author = {Cormier, Michelle V and Liang, Shano and Hamilton, Bill and LaLone, Nicolas and Bohrer, Rose and Toups Dugas, Phoebe O.},
title = {This Game SUX: Why \&amp; How to Design Sh@*!y User Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713246},
doi = {10.1145/3706598.3713246},
abstract = {While normative – “good” – game design and user experiences have been established, we look to games that challenge those notions. Intentional frustration and failure can be worthwhile. Through a reflexive thematic analysis of 31 games we identify how intentionally non-normative design choices lead to meaningful experiences. Working within the established Mechanics Dynamics Aesthetics (MDA) Game Design Framework, we lay out themes to design Shitty User Experiences (SUX). We contribute SUX MDA themes for designers and researchers to counter the status quo and identify new forms of play and interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {15},
keywords = {Shitty User Experience, SUX, jank, abusive game design, fumblecore, queer play},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641519.3657469,
author = {Ma, Jian and Liang, Junhao and Chen, Chen and Lu, Haonan},
title = {Subject-Diffusion: Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657469},
doi = {10.1145/3641519.3657469},
abstract = {Recent progress in personalized image generation using diffusion models has been significant. However, development in the area of open-domain and test-time fine-tuning-free personalized image generation is proceeding rather slowly. In this paper, we propose Subject-Diffusion, a novel open-domain personalized image generation model that, in addition to not requiring test-time fine-tuning, also only requires a single reference image to support personalized generation of single- or two-subjects in any domain. Firstly, we construct an automatic data labeling tool and use the LAION-Aesthetics dataset to construct a large-scale dataset consisting of 76M images and their corresponding subject detection bounding boxes, segmentation masks, and text descriptions. Secondly, we design a new unified framework that combines text and image semantics by incorporating coarse location and fine-grained reference image control to maximize subject fidelity and generalization. Furthermore, we also adopt an attention control mechanism to support two-subject generation. Extensive qualitative and quantitative results demonstrate that our method have certain advantages over other frameworks in single, multiple, and human-customized image generation.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {25},
numpages = {12},
keywords = {Diffusion, Open-Domain, Personalization, Text-to-Image},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@article{10.1145/3655615,
author = {White, Ryen W.},
title = {Advancing the Search Frontier with AI Agents},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/3655615},
doi = {10.1145/3655615},
abstract = {AI agents are extending the capabilities of traditional search engines to help users tackle complex tasks.},
journal = {Commun. ACM},
month = aug,
pages = {54–65},
numpages = {12}
}

@inproceedings{10.1145/3689492.3689811,
author = {Lesser, Stefan},
title = {A New Cognitive Perspective on Simplicity in System and Product Design},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3689811},
doi = {10.1145/3689492.3689811},
abstract = {What is simple? How can we make simple things? Simplicity seems easy to grasp but is surprisingly difficult to explain. “We know it when we see it”, but we don’t know how to describe it. This essay reflects on a number of observations about simplicity and complexity. It invites a perspective change towards a dynamical systems view of simplicity, explores how we can explain what makes things simple, and how we can utilize this knowledge as makers, creators, product and system designers to craft simple things.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {231–240},
numpages = {10},
keywords = {Architecture, Cognition, Complexity, Dynamical Systems, Product Design, Simplicity, System Design},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@inbook{10.5555/3716662.3716742,
author = {Lovato, Juniper and Zimmerman, Julia Witte and Smith, Isabelle and Dodds, Peter and Karson, Jennifer L.},
title = {Foregrounding Artist Opinions: A Survey Study on Transparency, Ownership, and Fairness in AI Generative Art},
year = {2025},
publisher = {AAAI Press},
abstract = {Generative AI tools are used to create art-like outputs and sometimes aid in the creative process. These tools have potential benefits for artists, but they also have the potential to harm the art workforce and infringe upon artistic and intellectual property rights. Without explicit consent from artists, Generative AI creators scrape artists' digital work to train Generative AI models and produce art-like outputs at scale. These outputs are now being used to compete with human artists in the marketplace as well as being used by some artists in their generative processes to create art. We surveyed 459 artists to investigate the tension between artists' opinions on Generative AI art's potential utility and harm. This study surveys artists' opinions on the utility and threat of Generative AI art models, fair practices in the disclosure of artistic works in AI art training models, ownership and rights of AI art derivatives, and fair compensation. Results show that a majority of artists believe creators should disclose what art is being used in AI training, that AI outputs should not belong to model creators, and express concerns about AI's impact on the art workforce and who profits from their art. We hope the results of this work will further meaningful collaboration and alignment between the art community and Generative AI researchers and developers.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {905–916},
numpages = {12}
}

@article{10.1145/3729396,
author = {Chattaraj, Rajrupa and Chimalakonda, Sridhar},
title = {NLP Libraries, Energy Consumption and Runtime: An Empirical Study},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3729396},
doi = {10.1145/3729396},
abstract = {In the realm of natural language processing (NLP), the rising computational demands of modern models bring energy efficiency to the forefront of sustainable computing. Preprocessing tasks, such as tokenization, stemming, and POS tagging, are critical steps in transforming raw text into structured formats suitable for machine learning models. However, despite their widespread use in numerous NLP pipelines, little attention has been given to their energy consumption. This empirical study evaluates and compares the energy consumption and runtime performance of three popular NLP libraries—NLTK, spaCy, and Gensim—across six common preprocessing tasks. We conducted a comprehensive comparison using three distinct datasets and six preprocessing tasks. Energy consumption was measured using the Intel-RAPL and NVIDIA-SMI interfaces, while runtime performance was recorded across all library-task combinations. The results reveal substantial discrepancies in energy consumption across the three libraries, with up to 93\% of cases exhibiting significant variations. Gensim showed superior efficiency in tokenization and stemming, while spaCy excelled in tasks like POS tagging and Named Entity Recognition (NER). These findings underscore the potential for optimizing NLP preprocessing tasks for energy efficiency. Our study highlights the untapped potential for improving energy efficiency in NLP pipelines. These insights emphasize the need for more focused research into energy-efficient NLP techniques, especially in the preprocessing phase, to support the development of greener, more sustainable computational models.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE126},
numpages = {24},
keywords = {NLP, RAPL, energy efficiency, libraries}
}

@proceedings{10.1145/3724504,
title = {ICIEAI '24: Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
year = {2024},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3715336.3735756,
author = {Sew, Cherie and Pareek, Saumya and Govers, Jarod and Sch\"{o}mbs, Sarah and Kelly, Ryan M. and Goncalves, Jorge},
title = {The Impact of Human-Likeness and Self-Disclosure on Message Acceptance in Virtual AI Influencers},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735756},
doi = {10.1145/3715336.3735756},
abstract = {Virtual AI-generated Influencers (VAIIs) are increasingly being used by corporations and public agencies, raising questions about how their visual design and communication strategies impact end-users’ propensity to accept the messages they deliver. We examined the impact of human-likeness (how closely a VAII resembles a human) and self-disclosure (whether the message contains personal information) on message acceptance, alongside dispositional factors like empathy and anthropomorphising tendencies. In a mixed-methods experiment, participants (N=120) watched short-form videos featuring VAIIs of varying human-likeness (High/Moderate-High/Moderate-Low/Low) and self-disclosure (present/absent). We observed the strongest message acceptance from the VAIIs with the lowest human-likeness, and message rejection for VAIIs with moderate to low human-likeness. Additionally, participants’ message acceptance was influenced by their empathy tendencies. Our qualitative analysis revealed further insights into participants’ perceptions of the human-likeness of VAIIs, their discomfort with self-disclosure, and their tendency to anthropomorphise VAIIs. These findings provide important implications for the design of VAIIs.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {1165–1178},
numpages = {14},
keywords = {Virtual Influencers, Message Acceptance, Human-likeness, Self-disclosure, Empathy, Artificial Intelligence, Social Media},
location = {
},
series = {DIS '25}
}

@inbook{10.5555/3716662.3716684,
author = {Carpenter, Daniel and Ezell, Carson},
title = {An FDA for AI? Pitfalls and Plausibility of Approval Regulation for Frontier Artificial Intelligence},
year = {2025},
publisher = {AAAI Press},
abstract = {Observers and practitioners of artificial intelligence (AI) have proposed an FDA-style licensing regime for the most advanced AI models, or 'frontier' models. In this paper, we explore the applicability of approval regulation - that is, regulation of a product that combines experimental minima with government licensure conditioned partially or fully upon that experimentation - to the regulation of frontier AI. There are a number of reasons to believe that approval regulation, simplistically applied, would be inapposite for frontier AI risks. Domains of weak fit include the difficulty of defining the regulated product, the presence of Knightian uncertainty or deep ambiguity about harms from AI, the potentially transmissible nature of risks, and distributed activities among actors involved in the AI lifecycle. We conclude by highlighting the role of policy learning and experimentation in regulatory development, describing how learning from other forms of AI regulation and improvements in evaluation and testing methods can help to overcome some of the challenges we identify.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {239–254},
numpages = {16}
}

@proceedings{10.1145/3702653,
title = {ICER '25: Proceedings of the 2025 ACM Conference on International Computing Education Research V.2},
year = {2025},
isbn = {9798400713415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3587102.3588794,
author = {Ouh, Eng Lieh and Gan, Benjamin Kok Siew and Jin Shim, Kyong and Wlodkowski, Swavek},
title = {ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588794},
doi = {10.1145/3587102.3588794},
abstract = {In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {54–60},
numpages = {7},
keywords = {Java, computer science education, object-oriented, programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3706598.3714200,
author = {Martinez, Lenny and Caramiaux, Baptiste and Fdili Alaoui, Sarah},
title = {Generative AI in Documentary Photography: Exploring Opportunities and Challenges for Visual Storytelling},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714200},
doi = {10.1145/3706598.3714200},
abstract = {Generative AI is increasingly used to create images from text, but its role in documentary photography remains under-explored. This paper investigates how generative AI can be integrated into documentary practice while maintaining ethical standards. Through interviews with six documentary photographers, we explored their views on AI’s potential to support community-driven storytelling. While AI presents opportunities for creative expression and community involvement, concerns about trust, authenticity, and decontextualization of images persist. Photographers expressed doubts about AI’s ability to accurately represent lived experiences, fearing it could compromise narrative integrity. Our findings suggest that AI tools should be designed to enhance collaboration and transparency in storytelling, complementing rather than replacing traditional documentary methods. This study contributes to the ongoing discourse on AI in photography, advocating for the development of tools that preserve the ethical foundations of documentary storytelling while empowering communities.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {329},
numpages = {13},
keywords = {Generative AI, Documentary photography, Visual storytelling, Text-to-image generation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713281,
author = {Tao, Ye and Fu, Xiaohui and Wu, Jiaying and Bian, Ze and Zhu, Aiyu and Bao, Qi and Zheng, Weiyue and Wang, Yubo and Zhu, Bin and Yang, Cheng and Zhou, Chuyi},
title = {AIFiligree: A Generative AI Framework for Designing Exquisite Filigree Artworks},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713281},
doi = {10.1145/3706598.3713281},
abstract = {Filigree art, which represents typical intricate metalwork, has been captivating audiences worldwide with its delicate lace-like patterns and interwoven metal wires’ refined aesthetics. Particularly, Chinese Intangible Cultural Heritage filigree craftsmanship has a unique aesthetic value in fine patterns and complex three-dimensional shapes. However, designing and creating filigree artworks is a labor-intensive and technically complex task and often requires extensive training and a deep understanding of the craft, which limits its design aesthetic and cultural continuity. Aiming to overcome these challenges, this study proposes an artificial intelligence (AI) -aided method that uses AI-generated content (AIGC) technology to accelerate the visualization process of this time-consuming and intricate craft by investigating the role of AI in craft design. First, a comprehensive study of filigree art culture is conducted to identify more than ten historic filigree techniques to obtain AI opportunities. Then, an AI-powered framework called AIFiligree is developed by optimizing culture-based labels and training parameters, enabling the generation of highly authentic fine filigree structures. Further, user workflows are introduced to support diverse design scenarios. Through user studies involving 22 filigree experts and 16 designers, we finally gained insights into AI’s opportunities and challenges in cultural learning, expression, and design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {658},
numpages = {18},
keywords = {Filigree, AIGC, AI design tools, Cultural intangible culture heritage},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3664646.3664772,
author = {Kouemo Ngassom, Sylvain and Moradi Dakhel, Arghavan and Tambon, Florian and Khomh, Foutse},
title = {Chain of Targeted Verification Questions to Improve the Reliability of Code Generated by LLMs},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664772},
doi = {10.1145/3664646.3664772},
abstract = {LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential to generate code that fulfills a programming task described in a natural language description, referred to as a prompt. The widespread accessibility of these assistants enables users with diverse backgrounds to generate code and integrate it into software projects. However, studies show that code generated by LLMs is prone to bugs and may miss various corner cases in task specifications. Presenting such buggy code to users can impact their reliability and trust in LLM-based assistants. Moreover, significant efforts are required by the user to detect and repair any bug present in the code, especially if no test cases are available. In this study, we propose a self-refinement method aimed at improving the reliability of code generated by LLMs by minimizing the number of bugs before execution, without human intervention, and in the absence of test cases. Our approach is based on targeted Verification Questions (VQs) to identify potential bugs within the initial code. These VQs target various nodes within the Abstract Syntax Tree (AST) of the initial code, which have the potential to trigger specific types of bug patterns commonly found in LLM-generated code. Finally, our method attempts to repair these potential bugs by re-prompting the LLM with the targeted VQs and the initial code. Our evaluation, based on programming tasks in the CoderEval dataset, demonstrates that our proposed method outperforms state-of-the-art methods by decreasing the number of targeted errors in the code between 21\% to 62\% and improving the number of executable code instances to 13\%.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {122–130},
numpages = {9},
keywords = {Code Generation, Hallucination, Large Language Model, Reliability, Software Development},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@article{10.1145/3689040,
author = {Bomba, Federico and Men\'{e}ndez-Blanco, Mar\'{\i}a and Grigis, Paolo and Cremaschi, Michele and De Angeli, Antonella},
title = {The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689040},
doi = {10.1145/3689040},
abstract = {The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {75},
numpages = {23},
keywords = {Agency, Agential Realism, Large Language Models, AI and Art, Creative AI, Hallucination}
}

@proceedings{10.1145/3686852,
title = {SIGITE '24: Proceedings of the 25th Annual Conference on Information Technology Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {El Paso, TX, USA}
}

@proceedings{10.1145/3708036,
title = {ICCSMT '24: Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
year = {2024},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3721121,
author = {Liang, Shano and Chen, Max and Toups Dugas, Phoebe O. and Smith, Gillian and Bohrer, Rose},
title = {The Collaborative Sensemaking Play of Jubensha Games: A Deconstruction, Taxonomy, and Analysis},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3721121},
doi = {10.1145/3721121},
abstract = {Jubensha games, popular in China, combine storytelling, social deduction, and script-centered group play, sparking widespread interest among gamers and researchers worldwide. However, enthusiasts and researchers have struggled to accurately describe Jubensha, often defaulting to comparisons with genres like murder mystery and live-action role-playing games. This reliance on comparisons hinders efforts to generalize Jubensha or to deconstruct and adapt its unique design components, dynamics of player interaction, and playing experience into other games. This research provides a taxonomy and analysis of Jubensha games, based on a thematic analysis of over 80 Jubensha games accessed through mobile applications and physical copies. The analysis combines the authors’ positionalities as native Chinese and English speakers and lenses from close reading of the games, discourse analysis, and distributed cognition. We provide summative case studies to exemplify our taxonomy and discuss design implications for Jubensha games for future projects. Our work provides a descriptive tool and vocabulary for researchers and designers to facilitate communication and theorize the evolving Jubensha gaming phenomenon highlighting how gameplay centers collaborative sensemaking. In addition, we argue that the design of game narratives in Jubensha games, including structures in scripts and the evolving performance of players, can be generalized and transferred to the design of a wider range of analog and video games.},
journal = {ACM Games},
month = mar,
articleno = {6},
numpages = {34},
keywords = {Jubensha, murder mystery games, taxonomy, game analysis, game design, cross-cultural context}
}

@inproceedings{10.1145/3715336.3735730,
author = {Santos-Torres, Andr\'{e}s and de Torres Coll, Patricia and Bukits, Tam\'{a}s and Peris\'{e}, Ram\'{o}n and Cabrero Barros, Sergio},
title = {The XR Table: Envisioning The Future of Remote Dining Experiences Using Immersive Telepresence},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735730},
doi = {10.1145/3715336.3735730},
abstract = {Eating is a vital, social, and intimate experience. Eating with others positively influences our health and mood and enhances our social relationships. However, sometimes, we lack the time, or the circumstances do not allow us to have this intimate experience physically. Current technology, such as video calls, somehow helps bridge the gap of physicality. However, they provide only a fraction of the social experience that face-to-face interaction allows. Recent progress in Immersive Telepresence and eXtended Reality (XR) enables an opportunity to redefine digital commensality, not only to overcome the gap of physical distance, but also to go beyond and redefine the experience of eating. In this paper, we–a multidisciplinary team of technology and commensality researchers–envision the future of digital commensality through immersive technology. To this end, we conducted two participatory co-design workshops and used iterative analysis to identify a set of design criteria that were applied to a working prototype system: the XR Table.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {1674–1690},
numpages = {17},
keywords = {Participatory Design, Digital Commensality, Volumetric Video, Social XR},
location = {
},
series = {DIS '25}
}

@proceedings{10.1145/3678429,
title = {ICHMI '24: Proceedings of the 2024 4th International Conference on Human-Machine Interaction},
year = {2024},
isbn = {9798400716812},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@inproceedings{10.1145/3661167.3661220,
author = {G\'{o}mez-Abajo, Pablo and P\'{e}rez-Soler, Sara and Ca\~{n}izares, Pablo C. and Guerra, Esther and de Lara, Juan},
title = {Mutation Testing for Task-Oriented Chatbots},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661220},
doi = {10.1145/3661167.3661220},
abstract = {Conversational agents, or chatbots, are increasingly used to access all sorts of services using natural language. While open-domain chatbots – like ChatGPT – can converse on any topic, task-oriented chatbots – the focus of this paper – are designed for specific tasks, like booking a flight, obtaining customer support, or setting an appointment. Like any other software, task-oriented chatbots need to be properly tested, usually by defining and executing test scenarios (i.e., sequences of user-chatbot interactions). However, there is currently a lack of methods to quantify the completeness and strength of such test scenarios, which can lead to low-quality tests, and hence to buggy chatbots. To fill this gap, we propose adapting mutation testing (MuT) for task-oriented chatbots. To this end, we introduce a set of mutation operators that emulate faults in chatbot designs, an architecture that enables MuT on chatbots built using heterogeneous technologies, and a practical realisation as an Eclipse plugin. Moreover, we evaluate the applicability, effectiveness and efficiency of our approach on open-source chatbots, with promising results.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {232–241},
numpages = {10},
keywords = {Botium, Dialogflow, Mutation testing, Rasa, Task-oriented chatbots},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1145/3715758,
author = {Sovrano, Francesco and Bauer, Adam and Bacchelli, Alberto},
title = {Large Language Models for In-File Vulnerability Localization Can Be “Lost in the End”},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3715758},
doi = {10.1145/3715758},
abstract = {Traditionally, software vulnerability detection research has focused on individual small functions due to earlier language processing technologies’ limitations in handling larger inputs. However, this function-level approach may miss bugs that span multiple functions and code blocks. Recent advancements in artificial intelligence have enabled processing of larger inputs, leading everyday software developers to increasingly rely on chat-based large language models (LLMs) like GPT-3.5 and GPT-4 to detect vulnerabilities across entire files, not just within functions. This new development practice requires researchers to urgently investigate whether commonly used LLMs can effectively analyze large file-sized inputs, in order to provide timely insights for software developers and engineers about the pros and cons of this emerging technological trend. Hence, the goal of this paper is to evaluate the effectiveness of several state-of-the-art chat-based LLMs, including the GPT models, in detecting in-file vulnerabilities. We conducted a costly investigation into how the performance of LLMs varies based on vulnerability type, input size, and vulnerability location within the file. To give enough statistical power (β ≥ .8) to our study, we could only focus on the three most common (as well as dangerous) vulnerabilities: XSS, SQL injection, and path traversal. Our findings indicate that the effectiveness of LLMs in detecting these vulnerabilities is strongly influenced by both the location of the vulnerability and the overall size of the input. Specifically, regardless of the vulnerability type, LLMs tend to significantly (p &lt; .05) underperform when detecting vulnerabilities located toward the end of larger files—a pattern we call the lost-in-the-end effect. Finally, to further support software developers and practitioners, we also explored the optimal input size for these LLMs and presented a simple strategy for identifying it, which can be applied to other models and vulnerability types. Eventually, we show how adjusting the input size can lead to significant improvements in LLM-based vulnerability detection, with an average recall increase of over 37\% across all models.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE041},
numpages = {23},
keywords = {Code Context, In-File Vulnerability Detection, Large Language Models, Path Traversal, SQL Injection, XSS, ‘Lost-in-the-End’ Issue}
}

@article{10.1145/3747288,
author = {Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Du, Xiaoning and Xing, Zhenchang},
title = {Bypassing Guardrails: Lessons Learned from Red Teaming ChatGPT},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3747288},
doi = {10.1145/3747288},
abstract = {Warning: this paper may contain content that is offensive or upsetting.Ethical and social risks persist as a crucial yet challenging topic in human-artificial Intelligence interactions, especially in ensuring the safe usage of natural language processing (NLP). The emergence of large language models (LLMs) like ChatGPT introduces the potential for exacerbating this concern. However, prior works on the ethics and risks of emergent LLMs either overlook the practical implications in real-world scenarios, lag behind rapid NLP advancements, lack user consensus on ethical risks, or fail to holistically address the entire spectrum of ethical considerations. In this paper, we comprehensively evaluate, qualitatively explore and catalog ethical dilemmas and risks in ChatGPT through benchmarking with eight representative datasets and red teaming involving diverse case studies. Our findings show that while ChatGPT demonstrates superior safety performance on benchmark datasets, its guardrails can be bypassed via our manually curated examples, revealing not only the limitations of current benchmarks for risk assessment but also unexplored risks in five distinct scenarios, including social bias in code generation, bias in cross-lingual question answering, toxic language in personalized dialogue, misleading information from hallucination, and prompt injections for unethical behaviors. We conclude with implications from red teaming ChatGPT and recommendations for designing future responsible large language models.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
keywords = {AI Ethics, Red Teaming, Large Language Models}
}

@inproceedings{10.1145/3689484.3690738,
author = {Greiner, Sandra and B\"{u}hlmann, Noah and Ohrndorf, Manuel and Tsigkanos, Christos and Nierstrasz, Oscar and Kehrer, Timo},
title = {Automated Generation of Code Contracts: Generative AI to the Rescue?},
year = {2024},
isbn = {9798400712111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689484.3690738},
doi = {10.1145/3689484.3690738},
abstract = {Design by Contract represents an established, lightweight paradigm for engineering reliable and robust software systems by specifying verifiable expectations and obligations between software components. Due to its laborious nature, developers hardly adopt Design by Contract in practice.    A plethora of research on (semi-)-automated inference to reduce the manual burden has not improved the adoption of so-called code contracts in practice.    This paper examines the potential of Generative AI to automatically generate code contracts in terms of pre- and postconditions for any Java project without requiring any additional auxiliary artifact.    To fine-tune two state-of-the-art Large Language Models, CodeT5 and CodeT5+, we derive a dataset of more than 14k Java methods comprising contracts in form of Java Modeling Language (JML) annotations, and train the models on the task of generating contracts.    We examine the syntactic and semantic validity of the contracts generated for software projects not used in the fine-tuning and find that more than 95\% of the generated contracts are syntactically correct and exhibit remarkably high completeness and semantic correctness.    To this end, our fully automated method sets the stage for future research and eventual broader adoption of Design by Contract in software development practice.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {1–14},
numpages = {14},
keywords = {Design by Contract, Generative AI, Large Language Models, Software Verification},
location = {Pasadena, CA, USA},
series = {GPCE '24}
}

@article{10.1145/3724128,
author = {Dar, Farooq Ayoub and Olapade, Mayowa and Ottun, Abdul-rasheed and Yin, Zhigang and Liyanage, Mohan and Norbisrath, Ulrich and Radeta, Marko and Silva, Francisco and Su, Xiang and Edinger, Janick and Nurmi, Petteri and Flores, Huber},
title = {TOAD: Profiling and Evaluating 3D Printed IoT Rapid Prototype Designs},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3724128},
doi = {10.1145/3724128},
abstract = {3D printing has revolutionized DIY (Do-It-Yourself) IoT prototyping, enabling cost-effective, creative custom device creation. However, this freedom also presents challenges due to the interplay between components within an IoT design, which can influence the overall utility and performance of the prototype. Optimizing these designs is difficult due to limited means of estimating their efficacy. To address this, we introduce TOAD, a novel tool for profiling IoT prototypes and gauging their performance impact. TOAD uses thermal imaging and video analysis to extract and compare design performance characteristics. Unlike existing solutions that only profile overall performance, our tool assesses component interactions and overall design effects. It offers an affordable, non-intrusive method without needing device access or code instrumentation. Extensive benchmarks show TOAD accurately extracts performance data, aiding in selecting the best design for IoT applications. Additionally, it provides insights into how casing factors like thickness and material influence thermal behavior and performance. We demonstrate practical applications by optimizing offloading decisions based on thermal behavior, highlighting casing impacts on design performance. TOAD paves the way for efficient IoT prototype designs, offering a better understanding of component interactions and significantly enhancing the utility of custom IoT designs and their effectiveness.},
journal = {ACM Trans. Internet Things},
month = may,
articleno = {15},
numpages = {31},
keywords = {Pervasive sensing, Internet of Things, rapid prototyping, 3D printing, thermal imaging}
}

@inproceedings{10.1109/SC41406.2024.00010,
author = {Singh, Siddharth and Singhania, Prajwal and Ranjan, Aditya and Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Jain, Neel and Hans, Abhimanyu and Shu, Manli and Tomar, Aditya and Goldstein, Tom and Bhatele, Abhinav},
title = {Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00010},
doi = {10.1109/SC41406.2024.00010},
abstract = {Training and fine-tuning large language models (LLMs) with hundreds of billions to trillions of parameters requires tens of thousands of GPUs, and a highly scalable software stack. In this work, we present a novel four-dimensional hybrid parallel algorithm implemented in a highly scalable, portable, open-source framework called AxoNN. We describe several performance optimizations in AxoNN to improve matrix multiply kernel performance, overlap non-blocking collectives with computation, and performance modeling to choose performance optimal configurations. These have resulted in unprecedented scaling and peak flop/s (bf16) for training of GPT-style transformer models on Perlmutter (620.1 Petaflop/s), Frontier (1.381 Exaflop/s) and Alps (1.423 Exaflop/s).While the abilities of LLMs improve with the number of trainable parameters, so do privacy and copyright risks caused by memorization of training data, which can cause disclosure of sensitive or private information at inference time. We highlight this side effect of scale through experiments that explore "catastrophic memorization," where models are sufficiently large to memorize training data in a single pass, and present an approach to prevent it. As part of this study, we demonstrate fine-tuning of a 405-billion parameter LLM using AxoNN on Frontier.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {4},
numpages = {14},
keywords = {GPGPUs, asynchrony, collective communication, large language models, parallel training},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@article{10.1145/3708526,
author = {Moreira, Ana and Lago, Patricia and Heldal, Rogardt and Betz, Stefanie and Brooks, Ian and Capilla, Rafael and Coroam\u{a}, Vlad Constantin and Duboc, Leticia and Fernandes, Jo\~{a}o Paulo and Leifler, Ola and Nguyen, Ngoc-Thanh and Oyedeji, Shola and Penzenstadler, Birgit and Peters, Anne-Kathrin and Porras, Jari and Venters, Colin C.},
title = {A Roadmap for Integrating Sustainability into Software Engineering Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708526},
doi = {10.1145/3708526},
abstract = {The world faces escalating crises: record-breaking temperatures, widespread fires, severe flooding, increased oceanic microplastics, and unequal resource distribution. Academia introduces courses around sustainability to meet the new demand, but software engineering education lags behind. While software systems contribute to environmental issues through high energy consumption, they also hold the potential for solutions, such as more efficient and equitable resource management. Yet, sustainability remains a low priority for many businesses, including those in the digital sector. Business as usual is no longer viable. A transformational change in software engineering education is urgently needed. We must move beyond traditional curriculum models and fully integrate sustainability into every aspect of software development. By embedding sustainability as a core competency, we can equip future engineers not only to minimise harm but also to innovate solutions that drive positive, sustainable change. Only with such a shift can software engineering education meet the demands of a world in crisis and prepare students to lead the next generation of sustainable technology. This article discusses a set of challenges and proposes a customisable education roadmap for integrating sustainability into the software engineering curricula. These challenges reflect our perspective on key considerations, stemming from regular, intensive discussions in regular workshops among the authors and the community, as well as our extensive research and teaching experience in the field.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {139},
numpages = {27},
keywords = {Software engineering, Sustainability, Computing, Education, Software sustainability, Sustainable software, Sustainable development goals, Software competencies, Sustainability skills}
}

@article{10.1145/3712300,
author = {Wang, Zhiyuan and Yuan, Fangxu and LeBaron, Virginia and Flickinger, Tabor and Barnes, Laura E.},
title = {PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712300},
doi = {10.1145/3712300},
abstract = {Effective patient-provider communication is crucial in clinical care, directly impacting patient outcomes and quality of life. Traditional evaluation methods, such as human ratings, patient feedback, and provider self-assessments, are often limited by high costs and scalability issues. Although existing natural language processing (NLP) techniques show promise, they struggle with the nuances of clinical communication and require sensitive clinical data for training, reducing their effectiveness in real-world applications. Emerging large language models (LLMs) offer a new approach to assessing complex communication metrics, with the potential to advance the field through integration into passive sensing and just-in-time intervention systems. This study explores LLMs as evaluators of palliative care communication quality, leveraging their linguistic, in-context learning, and reasoning capabilities. Specifically, using simulated scripts crafted and labeled by healthcare professionals, we test proprietary models (e.g., GPT-4) and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset generated by GPT-4 to evaluate clinical conversations, to identify key metrics such as ‘understanding’ and ‘empathy’. Our findings demonstrated LLMs’ superior performance in evaluating clinical communication, providing actionable feedback with reasoning, and demonstrating the feasibility and practical viability of developing in-house LLMs. This research highlights LLMs’ potential to enhance patient-provider interactions and lays the groundwork for downstream steps in developing LLM-empowered clinical health systems.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = jan,
keywords = {Patient-Provider Communication, Large Language Models, Healthcare, Palliative Care}
}

@proceedings{10.1145/3675812,
title = {ICDEL '24: Proceedings of the 2024 9th International Conference on Distance Education and Learning},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@article{10.1109/TCBB.2023.3311444,
author = {Liu, Ran and Hu, Ye-Fan and Du, Jin and Zhang, Bao-Zhong and Yau, Thomas and Fan, Xiaodan and Huang, Jian-Dong},
title = {Family-Specific Training Improves Linear B Cell Epitope Prediction for Emerging Viruses},
year = {2023},
issue_date = {Nov.-Dec. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2023.3311444},
doi = {10.1109/TCBB.2023.3311444},
abstract = {The rational design of vaccines and antibody-based therapeutics against newly emerging viruses relies on B cell epitopes mainly. To predict the B cell epitopes of a novel virus, several algorithms have been developed. While most existing algorithms are trained on a dataset in which B cell epitopes are classified as ‘Positive’ or ‘Negative’. However, we found that training on such data contaminates the target pattern of specific viruses, leading to inaccurate predictions in some cases. In this paper, we introduce a novel framework for predicting linear B cell epitopes of novel viruses by exclusively using highly similar viruses for training data. We employed kernel regression based on seropositive rates, which are the percentages of seropositive samples among the population, to predict the potential epitopes. To assess our method, we conducted simulations and utilized two real-world datasets. Our method significantly outperformed other existing methods on the testing data of four viruses with seropositive rates. Also, our strategy showed a better prediction in a larger dataset from the IEDB. Thus, a novel framework providing better linear B cell prediction of newly emerging viruses is established, which will benefit the rational design of vaccines and antibody-based therapeutics in the future.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = sep,
pages = {3669–3680},
numpages = {12}
}

@inproceedings{10.1145/3715336.3735735,
author = {Holopainen, Jussi and Huang, Yuxuan and Shin, Joongi and Nissinen, Erkka and Lucero, Andr\'{e}s},
title = {Infinity Book: Speculating Literary Expressions in the Age of Generative AI},
year = {2025},
isbn = {9798400714856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715336.3735735},
doi = {10.1145/3715336.3735735},
abstract = {This paper explores the ethical, social, political, and philosophical implications of generative AI (GenAI) on human creativity, contributing to the current discussions on the impact of AI. We use speculative and critical design as our approach to avoid abstract guesswork and provide more nuanced and concrete insights into the matter at hand. We conducted five speculative design workshops centered on Infinity Book, a fictional system capable of generating any kind of literary work. Participants used brainwriting, the Future Ripples method, and dialogue-labs to explore potential futures and socio-material impacts of such technology. Reflexive Thematic Analysis was employed to analyze the results from the workshops, and we developed twelve design fictions that illustrate diverse uses and societal implications of GenAI. Based on these results, we formulated three strong concepts, Authenticity, Creative Agency, and Liveness, that link concrete design considerations with broader philosophical discussions.},
booktitle = {Proceedings of the 2025 ACM Designing Interactive Systems Conference},
pages = {1430–1454},
numpages = {25},
keywords = {speculative design, generative AI, literary expression},
location = {
},
series = {DIS '25}
}

@proceedings{10.1145/3723890,
title = {CNSCT '25: Proceedings of the 2025 4th International Conference on Cryptography, Network Security and Communication Technology},
year = {2025},
isbn = {9798400712623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3644032.3644456,
author = {Canizares, Pablo C. and \'{A}vila, Daniel and Perez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644456},
doi = {10.1145/3644032.3644456},
abstract = {Conversational agents - or chatbots - are increasingly used as the user interface to many software services. While open-domain chatbots like ChatGPT excel in their ability to chat about any topic, task-oriented conversational agents are designed to perform goal-oriented tasks (e.g., booking or shopping) guided by a dialogue-based user interaction, which is explicitly designed. Like any kind of software system, task-oriented conversational agents need to be properly tested to ensure their quality. For this purpose, some tools permit defining and executing conversation test cases. However, there are currently no established means to assess the coverage of the design of a task-oriented agent by a test suite, or mechanisms to automate quality test case generation ensuring the agent coverage.To attack this problem, we propose test coverage criteria for task-oriented conversational agents, and define coverage-based strategies to synthesise test scenarios, some oriented to test case reduction. We provide an implementation of the criteria and the strategies that is independent of the agent development platform. Finally, we report on their evaluation on open-source Dialogflow and Rasa agents, and a comparison against a state-of-the-art testing tool. The experiment shows benefits in terms of test generation correctness, increased coverage and reduced testing time.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {23–33},
numpages = {11},
keywords = {testing, test suite generation, task-oriented conversational agents},
location = {Lisbon, Portugal},
series = {AST '24}
}

@inproceedings{10.14236/ewic/BCSHCI2023.11,
author = {Espinoza, Fernanda and Cook, Darren and Butler, Chris R. and Calvo, Rafael A.},
title = {Supporting dementia caregivers in Peru through chatbots: generative AI vs structured conversations.},
year = {2024},
isbn = {1234567891011},
publisher = {BCS Learning \&amp; Development Ltd},
address = {Swindon, GBR},
url = {https://doi.org/10.14236/ewic/BCSHCI2023.11},
doi = {10.14236/ewic/BCSHCI2023.11},
abstract = {In Peru, dementia caregivers face burnout, depression, stress, and financial strain. Addressing their needs involves tackling the intricacies of caregiving and managing emotional burdens. Chatbots can serve as a viable support mechanism in regions with limited resources. This study delves into the perceptions of dementia caregivers in Peru regarding a chatbot tailored to offer care navigation and emotional support. We divided the study into three phases: the initial stage encompassed engaging stakeholders to define design requirements for the chatbot; the second stage focused on the creation of ‘Ana’, a chatbot for dementia caregivers; and the final stage assessed the chatbot through interviews and a caregiver satisfaction survey. ‘Ana’ was tested in two configurations - one employed pre-defined conversation patterns, while the other harnessed generative AI for more dynamic responses. The findings reveal that caregivers seek immediate access to information on handling behavioural symptoms and a platform for emotional release. Moreover, participants preferred the generative AI alternative of Ana, as it was perceived to be more empathic and human-like. The participants valued the generative approach despite knowing the potential risk of receiving inaccurate information.},
booktitle = {Proceedings of the 36th International BCS Human-Computer Interaction Conference},
pages = {89–98},
numpages = {10},
keywords = {Dementia, Chatbot, Conversational design, Human-centred design, Generative AI, Caregiver support, Caregiver intervention},
location = {University of York, UK},
series = {BCS HCI '23}
}

@inproceedings{10.1145/3614419.3644003,
author = {Fernandez, Miriam and Bellog\'{\i}n, Alejandro and Cantador, Iv\'{a}n},
title = {Analysing the Effect of Recommendation Algorithms on the Spread of Misinformation},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644003},
doi = {10.1145/3614419.3644003},
abstract = {Recommendation algorithms (RAs) have been pointed out as one of the major culprits of misinformation spreading in the digital sphere.1 However, it is still unclear how these algorithms propagate misinformation, e.g., which particular recommendation approaches are more prone to suggest misinforming items, or which internal parameters of the algorithms could be influencing more on their misinformation propagation capacity. Motivated by this fact, in this work, we present an analysis of the effect of some of the most popular recommendation algorithms on the spread of misinformation on Twitter (X). A set of guidelines on how to adapt these algorithms is provided based on such analysis and a comprehensive review of the research literature.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {159–169},
numpages = {11},
keywords = {misinformation, recommender systems, social networks},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3706598.3713479,
author = {Mei, Yihan and Wu, Zhao and Yu, Junnan and Li, Wenan and Zhou, Zhibin},
title = {GeneyMAP: Exploring the Potential of GenAI to Facilitate Mapping User Journeys for UX Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713479},
doi = {10.1145/3706598.3713479},
abstract = {Generative AI (GenAI) has been widely applied in UX design, yet its potential in the Journey Map (JM) creation process remains under-explored. We conducted a formative study (N = 24) to identify designers’ needs for GenAI in JM creation, resulting in six design goals (e.g., Acting as Different Stakeholders) implemented in our tool, GeneyMAP. GeneyMAP streamlines the JM creation process, allowing designers to map interview data efficiently with flexibility, uncovering design opportunities through visual inspiration. A subsequent user study (N = 20) demonstrated that GeneyMAP, compared with the common tool, accelerated JM creation and fostered creativity mainly by providing diverse inspirations and facilitating progressive discussions. Our findings proved GeneyMAP’s utility and effectiveness while challenges in maintaining control and trust in GenAI outputs were noted. Our research highlights the promising role of GenAI in refining JM creation practices and suggests implications for incorporating GenAI in JM and design workflows.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {270},
numpages = {22},
keywords = {Generative AI, LLMs, Design Tool, UX Design, User Research, Journey Map},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3636555.3636921,
author = {Liu, Qinyi and Khalil, Mohammad and Jovanovic, Jelena and Shakya, Ronas},
title = {Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data Generation and Evaluation in Learning Analytics},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636921},
doi = {10.1145/3636555.3636921},
abstract = {Privacy poses a significant obstacle to the progress of learning analytics (LA), presenting challenges like inadequate anonymization and data misuse that current solutions struggle to address. Synthetic data emerges as a potential remedy, offering robust privacy protection. However, prior LA research on synthetic data lacks thorough evaluation, essential for assessing the delicate balance between privacy and data utility. Synthetic data must not only enhance privacy but also remain practical for data analytics. Moreover, diverse LA scenarios come with varying privacy and utility needs, making the selection of an appropriate synthetic data approach a pressing challenge. To address these gaps, we propose a comprehensive evaluation of synthetic data, which encompasses three dimensions of synthetic data quality, namely resemblance, utility, and privacy. We apply this evaluation to three distinct LA datasets, using three different synthetic data generation methods. Our results show that synthetic data can maintain similar utility (i.e., predictive performance) as real data, while preserving privacy. Furthermore, considering different privacy and data utility requirements in different LA scenarios, we make customized recommendations for synthetic data generation. This paper not only presents a comprehensive evaluation of synthetic data but also illustrates its potential in mitigating privacy concerns within the field of LA, thus contributing to a wider application of synthetic data in LA and promoting a better practice for open science.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {620–631},
numpages = {12},
keywords = {Generative adversarial network, Learning analytics, Privacy Preserving Technologies, Synthetic data generation},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3706598.3714146,
author = {Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani},
title = {Exploring Multimodal Generative AI for Education through Co-design Workshops with Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714146},
doi = {10.1145/3706598.3714146},
abstract = {Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {17},
keywords = {artificial intelligence, generative AI, large language models, multimodality, co-design, design principles, learning environment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714008,
author = {Flores-Saviaga, Claudia and Hanrahan, Benjamin V. and Imteyaz, Kashif and Clarke, Steven and Savage*, Saiph},
title = {The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714008},
doi = {10.1145/3706598.3714008},
abstract = {The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for “AI timeouts.” Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1164},
numpages = {17},
keywords = {generative ai, accessibility, ai coding assistants, assistive technology},
location = {
},
series = {CHI '25}
}

