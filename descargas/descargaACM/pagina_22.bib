@inproceedings{10.1145/3701716.3717539,
author = {Kanakaris, Nikos and Ping, Heng and Xiao, Xiongye and Ahmed, Nesreen K. and Luceri, Luca and Ferrara, Emilio and Bogdan, Paul},
title = {Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717539},
doi = {10.1145/3701716.3717539},
abstract = {Detecting organized political campaigns, commonly known as astroturf campaigns, is of paramount importance in fighting against disinformation on social media. Existing approaches for the identification of such organized actions employ techniques mostly from network science, graph machine learning and natural language processing. Their ultimate goal is to analyze the relationships and interactions (e.g. re-posting) among users and the textual similarities of their posts. Despite their effectiveness in recognizing astroturf campaigns, these methods face significant challenges, notably the class imbalance in available training datasets. To mitigate this issue, recent methods usually resort to data augmentation or increasing the number of positive samples, which may not always be feasible or sufficient in real-world settings. Following a different path, in this paper, we propose a novel framework for identifying astroturf campaigns based solely on large language models (LLMs), introducing a Balanced Retrieval-Augmented Generation (Balanced RAG) component. Our approach first gives both textual information concerning the posts (in our case tweets) and the user interactions of the social network as input to a language model. Then, through prompt engineering and the proposed Balanced RAG method, it effectively detects coordinated disinformation campaigns on ùïè (Twitter). The proposed framework does not require any training or fine-tuning of the language model. Instead, by strategically harnessing the strengths of prompt engineering and Balanced RAG, it facilitates LLMs to overcome the effects of class imbalance and effectively identify coordinated political campaigns. The experimental results demonstrate that by incorporating the proposed prompt engineering and Balanced RAG methods, our framework outperforms the traditional graph-based baselines, achieving 2\texttimes{}-3\texttimes{} improvements in terms of precision, recall and F1 scores.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2651‚Äì2660},
numpages = {10},
keywords = {class imbalance, disinformation spread, fake news detection, graph classification, graph-aware prompt engineering, large language models, organized disinformation campaign detection, prompt engineering, retrieval-augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3664647.3681289,
author = {Zhou, Peng and Cai, Dunbo and Du, Yujian and Zhang, Runqing and Ni, Bingbing and Qin, Jie and Qian, Ling},
title = {Edit3D: Elevating 3D Scene Editing with Attention-Driven Multi-Turn Interactivity},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681289},
doi = {10.1145/3664647.3681289},
abstract = {With the rise of new 3D representations like NeRF and 3D Gaussian splatting, creating realistic 3D scenes is easier than ever before. However, the incompatibility of these 3D representations with existing editing software has also introduced unprecedented challenges to 3D editing tasks. Although recent advances in text-to-image generative models have made some progress in 3D editing, these methods either lack precision or require users to manually specify the editing areas in 3D space, complicating the editing process. To overcome these issues, we propose Edit3D, an innovative 3D editing method designed to enhance editing quality. Specifically, we propose a multi-turn editing framework and introduce an attention-driven open-set segmentation (ADSS) technique within this framework. ADSS allows for more precise segmentation of parts, which enhances the editing precision and minimizes interference with pixels in areas that are not being edited. Additionally, we propose a fine-tuning phase, intended to further improve the overall editing quality without compromising the training efficiency. Experiments demonstrate that Edit3D effectively adjusts 3D scenes based on textual instructions. Through continuous and multiple turns of editing, it achieves more intricate combinations, enhancing the diversity of 3D editing effects. Code is available at https://github.com/PeterouZh/Edit3D.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3401‚Äì3410},
numpages = {10},
keywords = {3d editing, attention-driven, multi-turn editing},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3726302.3730008,
author = {Garetto, Michele and Cornacchia, Alessandro and Galante, Franco and Leonardi, Emilio and Nordio, Alessandro and Tarable, Alberto},
title = {Information Retrieval in the Age of Generative AI: The RGB Model},
year = {2025},
isbn = {9798400715921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726302.3730008},
doi = {10.1145/3726302.3730008},
abstract = {The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability. This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools. Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood. We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics. This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations. Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources. An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge. This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools.},
booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {602‚Äì612},
numpages = {11},
keywords = {automation bias, information quality, large language models, retrieval-augmented generation, stack exchange, web answering},
location = {Padua, Italy},
series = {SIGIR '25}
}

@proceedings{10.1145/3696500,
title = {ICBDDM '24: Proceedings of the 2024 International Conference on Big Data and Digital Management},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@article{10.1145/3641001,
author = {Jing, Felicia S. and Berger, Sara E. and Becerra Sandoval, Juana Catalina and Pepper, Kristin and Wheeler, April M. and Mayoral, Paula Redondo and Lokesh, Divya and Feng, Alice and Mijalkovic, Marija and Bao, Chaoyun and Dholakia, Sara and Goyal, Mohit},
title = {Designing for Agonism: 12 Workers' Perspectives on Contesting Technology Futures},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641001},
doi = {10.1145/3641001},
abstract = {In this paper, we gather 12 workers from a large technology company, as recent participants of a research initiative on the social impact of emerging technologies, to present a collaborative analysis of the opportunities and limitations of dissensus-based approaches to technology research and design. We introduce a series of speculative and deconstructive probes and present findings from their use in four collaborative design sessions. We then draw on the theoretical tradition of Agonism to identify moments of friction, refusal, and disagreement over the course of these sessions. We contend that this approach offers a politically important alternative to consensus-based collaborative design methods and can even surface new rhetorics of contestation within discourses on technology futures. We conclude with a discussion of the importance of worker-authored research and an initial set opportunities, challenges, and paradoxes as a resource for future efforts to "Design for Agonism."},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {162},
numpages = {25},
keywords = {agonism, agonistic participatory design, collaborative design, deconstruction, dissensus, emerging technologies, speculative design}
}

@inproceedings{10.1145/3648188.3675142,
author = {Aldous, Kholoud and Salminen, Joni and Farooq, Ali and Jung, Soon-Gyo and Jansen, Bernard},
title = {Using ChatGPT in Content Marketing: Enhancing Users‚Äô Social Media Engagement in Cross-Platform Content Creation through Generative AI},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3675142},
doi = {10.1145/3648188.3675142},
abstract = {As the integration of artificial intelligence into social media continues to attract attention, the key impacts on content marketing are still undefined. Initial studies have shown that language models are capable of producing content that is competitive with content created by humans. However, how can such content be tailored for different social media platforms as part of an organization‚Äôs content marketing strategy? To address this question, we evaluate the effectiveness of using GPT-4, to generate cross-platform content for Facebook, Instagram, and Twitter (currently X). Participants (N = 892) evaluated 30 AI-created content (ACC) and human-created content (HCC). Findings show that ACC scored higher on preference by users, call-to-action, and emotional responses than HCC for Facebook. However, AI‚Äôs advantage wanes on Twitter and Instagram, where posts are terser. The results imply that GPT-4 comprehends what type of content to create for different platforms, making it a useful tool for cross-platform content creation.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {376‚Äì383},
numpages = {8},
keywords = {Facebook, Generative AI, Instagram, Social media, Twitter},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1145/3700297.3700306,
author = {Gai, Erqi},
title = {The Effects of ChatGPT on English Language Learning in Regards to Language Proficiency and Learning Motivation},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700306},
doi = {10.1145/3700297.3700306},
abstract = {Making use of ChatGPT in language learning has been heatedly discussed in recent years. Former researchers have assessed its usability in English language learning by analyzing users‚Äô feedback, but only provide little information about how it specifically affects English language learning in regards to its language proficiency or language motivation. Henceforth, to fill the research void, this study is designed to analyze the effects of ChatGPT on English language learning concerning vocabulary learning, automated writing evaluation and writing ability, and learning motivation. By selecting eight targeted studies based on the STARLITE standards, the researcher reviewed the studies and briefly summarized the influences: 1) ChatGPT could assist in extending EFL students‚Äô vocabulary through completing text-based tasks; 2) ChatGPT could improve EFL students‚Äô writing ability via automated writing evaluation; 3) ChatGPT could motivate EFL students to learn due to its personalized replies and diverse forms of providing information. However, this study does not contain an analysis of its effects on English language learning in all aspects such as listening and speaking ability. Thus, further studies could probe into the effects of ChatGPT on other English language learning fields.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {43‚Äì53},
numpages = {11},
keywords = {ChatGPT, EFL, Language Learning, Language Proficiency, Learning Motivation},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3695080.3695149,
author = {Li, Shilong and Zhang, Li and Gu, Mengchen and Chan, Jian and Wu, Qi},
title = {Risk analysis and control of large artificial intelligence models},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695080.3695149},
doi = {10.1145/3695080.3695149},
abstract = {With the rapid development of artificial intelligence(AI) technology, large AI models have demonstrated immense potential and value in numerous fields. However, the security risks associated with large AI models have also increasingly garnered widespread attention. This paper first outlines the development status and characteristics of large AI models and provides a detailed classification and discussion of the security risks. Next, the paper analyzes the causes of these risks, delving into technical, talent, and policy perspectives. Lastly, the paper proposes countermeasures for the secure development of large AI models, including improving technical regulation, enhancing policy regulations, strengthening talent cultivation, and reinforcing international cooperation, with the aim of providing a theoretical reference for the healthy development of large AI models.},
booktitle = {Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
pages = {402‚Äì408},
numpages = {7},
location = {Dali, China},
series = {ICCBD '24}
}

@inproceedings{10.1145/3565066.3608691,
author = {Yoon, Harin and Jun, Soojin},
title = {Ethical Awareness of UXers in the Loop: Ethical Issues in the Uxer-AI Collaboration Process from a UX Perspective},
year = {2023},
isbn = {9781450399241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565066.3608691},
doi = {10.1145/3565066.3608691},
abstract = {Artificial Intelligence (AI) has emerged as a prominent collaborative tool across diverse domains, driving innovation in various tasks. However, this human‚ÄìAI process brings forth a range of ethical considerations that require careful examination. This study investigates the ethical concerns that arise during the user experience designer (UXer)‚ÄìAI co-creation process and the evolving role of UXers. Employing a mixed methods approach, combining observational task performance experiments and in-depth interviews, the study captures UXers' perceptions of ethical issues in the UXer-AI co-creation process. The findings shed light on three prominent ethical challenges in the UXer‚ÄìAI co-creation process: reliability, bias, and unemployment. Consequently, this study emphasizes the crucial role of UXers, such as fact-checking, empathy-based decision making, and effective communication with AI, mitigating these ethical challenges. These findings enhance our understanding of UXers' responsibilities and shed light on the potential of leveraging AI as an effective collaborative tool for task completion.},
booktitle = {Proceedings of the 25th International Conference on Mobile Human-Computer Interaction},
articleno = {6},
numpages = {6},
keywords = {AI Ethics, Co-Creation, Ethical UX, Generative AI, Uxer-AI Co-Creation Model},
location = {Athens, Greece},
series = {MobileHCI '23 Companion}
}

@inproceedings{10.1145/3672919.3672945,
author = {Chen, Hongzhi and Pang, Feng},
title = {A decision-support agent framework and its application in industry},
year = {2024},
isbn = {9798400718212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672919.3672945},
doi = {10.1145/3672919.3672945},
abstract = {With a rapid development of artificial intelligence generative content (AIGC), a set of human-machine interactive models have been changed. However, with limited understanding of the purposes of industry, even though fined-tuned by the professional data. The manuscript proposes a multi-role, self-closed-loop intelligent agent collaborative system framework (CISFA) that can compensate for the shortcomings of LLM in professional semantic understanding, multi-round self-interaction, and judgment and decision-making application scenes based on feedback and self-supervision between multiple role agents in multi-round Q&amp;A based decision-making scenarios. Meanwhile, feasibility of applying medium-sized LLMs to aforementioned industry scenarios to achieve performance similar to that of very large-scale base models have also been considered. Through joint application with AIGC large models in three standard industry scenarios: drilling well control, device asset operation and maintenance management, as well as refining device operation guidance searching, it is proven that CISFA agent framework is effective in reducing the engineering application threshold of large models, simplify the prompt process and interpretation of industry mechanisms, and reducing application costs since medium-sized LLM been proven to show similar performance as very-large LLM by the allied application with CISFA.},
booktitle = {Proceedings of the 2024 3rd International Conference on Cyber Security, Artificial Intelligence and Digital Economy},
pages = {131‚Äì137},
numpages = {7},
location = {Nanjing, China},
series = {CSAIDE '24}
}

@inproceedings{10.1145/3706599.3706674,
author = {Paradis, Elise and Murillo, Ambar and Pandey, Maulishree and D'Angelo, Sarah and Macvean, Andrew and Ferrari-Church, Ben and Hughes, Matthew},
title = {Creating benchmarkable components to measure the quality of AI-enhanced developer tools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706674},
doi = {10.1145/3706599.3706674},
abstract = {In the AI community, benchmarks to evaluate model quality are well established, but an equivalent approach to benchmarking products built upon generative AI models is still missing. This has had two consequences. First, it has made teams focus on model quality over the developer experience, while successful products combine both. Second, product team have struggled to answer questions about their products in relation to their competitors.In this case study, we share: (1) our process to create robust, enterprise-grade and modular components to support the benchmarking of the developer experience (DX) dimensions of our team‚Äôs AI for code offerings, and (2) the components we have created to do so, including demographics and attitudes towards AI surveys, a benchmarkable task, and task and feature surveys. By doing so, we hope to lower the barrier to the DX benchmarking of genAI-enhanced code products.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {665},
numpages = {14},
keywords = {AI UX metrics; benchmarking; human computer interaction; evaluation; impact of AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3643690.3648239,
author = {Turhan, Yagmur and Buehrle, Deborah and Herzwurm, Georg},
title = {Developing a Taxonomy for Agile Scaling Frameworks},
year = {2024},
isbn = {9798400705717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643690.3648239},
doi = {10.1145/3643690.3648239},
abstract = {In the last decade, various scalable agile frameworks have emerged to scale the benefits of agility to wider organizational levels and have become increasingly popular in practice. However, the variety of frameworks has not been widely understood yet. The aim of this paper is to provide a well-organized understanding of the primary dimensions and characteristics of these frameworks. To this end, a taxonomy for scaling agile frameworks was created utilising a systematic method for taxonomy development. The basis for the formal and content-related creation of the taxonomy is a systematic and focused literature review, followed by a qualitative text analysis to extract key framework characteristics, concentrating on the four agile scaling frameworks Scaled Agile Framework, Large-Scale Scrum, Disciplined Agile Delivery and Scrum@Scale. For the validation of the proposed taxonomy, an exemplary categorisation of 2 frameworks in the taxonomy was performed.},
booktitle = {Proceedings of the 7th ACM/IEEE International Workshop on Software-Intensive Business},
pages = {40‚Äì47},
numpages = {8},
keywords = {scaled agile, scaled agile software development, scaled agile frameworks, SAFe, LeSS, S@S, DAD, taxonomy},
location = {Lisbon, Portugal},
series = {IWSiB '24}
}

@inproceedings{10.1145/3677525.3678642,
author = {Herodotou, Christothea and Kenny, Ian and Scanlon, Eileen},
title = {Democratising Research Practices through Community Citizen Science},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677525.3678642},
doi = {10.1145/3677525.3678642},
abstract = {The involvement of the general public or volunteers in research has evolved over time. Terms such as ‚Äòsubjects‚Äô have been replaced by ‚Äòparticipants‚Äô and are accompanied by an aspiration to actively engage people in research. Under the banner of Community Citizen Science (CCS), we have seen the public collecting or processing data to support activities led by professional scientists, while recently, we observed a growing interest in bringing together members of communities to examine personally relevant topics and identify solutions that best match their needs. In this study, we captured the perceptions of professional scientists about participants' engagement in research activities. We interviewed 14 academics and researchers from The Open University UK who conduct primary research with human participants, including those explicitly involved in CCS and participatory research. We identified varied roles participants currently have in research, diverse perceptions about the benefits participants may experience from taking part in research, and challenges faced when certain forms of CCS are deployed. Insights from this study resulted in proposing a practical CCS framework with five functions that can enable the democratisation of research practices in the future.&nbsp;},
booktitle = {Proceedings of the 2024 International Conference on Information Technology for Social Good},
pages = {68‚Äì75},
numpages = {8},
keywords = {Community Citizen Science, democratization, higher education, participants, research practices},
location = {Bremen, Germany},
series = {GoodIT '24}
}

@proceedings{10.1145/3622759,
title = {DLS 2023: Proceedings of the 19th ACM SIGPLAN International Symposium on Dynamic Languages},
year = {2023},
isbn = {9798400703898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 19th edition  of the Dynamic Language Symposium (DLS 2023),  co-located with SPLASH 2023 in Cascais, Portugal.  After about two decades of dynamic language research and DLS, it is time to reflect  and look forward to what the next two decades will bring. This year‚Äôs DLS is  therefore a special one focusing on the Future of Dynamic Languages. To do  the notion of symposium justice, we invited speakers to present  their opinions on where dynamic languages might be, will be, or should be  in the next twenty years.},
location = {Cascais, Portugal}
}

@inproceedings{10.1145/3706468.3706545,
author = {Jin, Yueqiao and Yang, Kaixun and Yan, Lixiang and Echeverria, Vanessa and Zhao, Linxuan and Alfredo, Riordan and Milesi, Mikaela and Fan, Jie Xiang and Li, Xinyu and Gasevic, Dragan and Martinez-Maldonado, Roberto},
title = {Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706545},
doi = {10.1145/3706468.3706545},
abstract = {Learning analytics dashboards (LADs) simplify complex learner data into accessible visualisations, providing actionable insights for educators and students. However, their educational effectiveness has not always matched the sophistication of the technology behind them. Explanatory and interactive LADs, enhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic, dialogue-based interactions with data visualisations and offering personalised feedback through text. Yet, the effectiveness of these tools may be limited by learners‚Äô varying levels of GenAI literacy, a factor that remains underexplored in current research. This study investigates the role of GenAI literacy in learner interactions with conventional (reactive) versus scaffolding (proactive) chatbot-assisted LADs. Through a comparative analysis of 81 participants, we examine how GenAI literacy is associated with learners‚Äô ability to interpret complex visualisations and their cognitive processes during interactions with chatbot-assisted LADs. Results show that while both chatbots significantly improved learner comprehension, those with higher GenAI literacy benefited the most, particularly with conventional chatbots, demonstrating diverse prompting strategies. Findings highlight the importance of considering learners‚Äô GenAI literacy when integrating GenAI chatbots in LADs and educational technologies. Incorporating scaffolding techniques within GenAI chatbots can be an effective strategy, offering a more guided experience that reduces reliance on learners‚Äô GenAI literacy.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {579‚Äì590},
numpages = {12},
keywords = {learning analytics dashboard, generative AI literacy, generative AI chatbots, data visualisation},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641399.3641437,
author = {Naik, Ravindra and Rajbhoj, Asha and Patwardhan, Manasi and Medicherla, Raveendra Kumar},
title = {Workshop Report on Generative AI-based Software Engineering},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641399.3641437},
doi = {10.1145/3641399.3641437},
abstract = {The co-authors have organized and conducting the Generative AI-based Software Engineering workshop, co-located with the 17th Innovations in Software Engineering Conference (ISEC) at Bangalore, India on 22nd Feb. 2024. This report briefly describes the objectives and brief contents of the workshop, and hoping that the execution of the planned contents during the workshop will meet the set objectives.},
booktitle = {Proceedings of the 17th Innovations in Software Engineering Conference},
articleno = {21},
numpages = {5},
location = {Bangalore, India},
series = {ISEC '24}
}

@article{10.1145/3642979.3642996,
author = {Sanderson, Mark and Lobato, Ramon and Hegarty, Kieran and Given, Lisa M. and Shah, Chirag},
title = {Report on The Web Search Revolution: Symposium},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3642996},
doi = {10.1145/3642979.3642996},
abstract = {This report describes a one-day symposium held at RMIT University that celebrated two milestone anniversaries in Web search: the launch in 1993 of JumpStation, the first modern web search engine; and the 25th anniversary since Google was incorporated as a company in 1998. The report describes the keynote presentations from Microsoft Research leader, Susan Dumais and University of Washington professor, Chirag Shah as well as three panel sessions involving leading researchers across Australia in both academia and industry. The symposium explored the impact and future directions of the web search revolution.Date: 17 August 2023.Website: https://www.admscentre.org.au/event/web-search-revolution/.},
journal = {SIGIR Forum},
month = jan,
articleno = {14},
numpages = {10}
}

@proceedings{10.1145/3722237,
title = {ICAIE '24: Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
year = {2024},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3613905.3644060,
author = {Gorichanaz, Tim},
title = {Toward Humanity-Centered Design without Hubris},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3644060},
doi = {10.1145/3613905.3644060},
abstract = {Humanity-centered design is a concept of emerging interest in HCI, one motivated by the limitations of human-centered design. As discussed to date, humanity-centered design is compatible with but goes beyond human-centered design in that it considers entire ecosystems and populations over the long term and centers participatory design. Though the intentions of humanity-centered design are laudable, current articulations of humanity-centered design are incoherent in a number of ways, leading to questions of how exactly it can or should be implemented. In this article, I delineate four ways in which humanity-centered design is incoherent‚Äîwhich can be boiled down to a tendency toward hubris‚Äîand propose a more fruitful way forward, a humble approach to humanity-centered design. Rather than a contradiction in terms, ‚Äúhumility‚Äù here refers to an organic, piecemeal, patterns-based approach to design that will be good for our being on this earth.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {Christopher Alexander, Don Norman, critique, human-centered design, humanity-centered design},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3696630.3727255,
author = {Wang, Tianjia and Trimble, Matthew and Brown, Chris},
title = {DevCoach: Supporting Students Learning the Software Development Life Cycle with a Generative AI powered Multi-Agent System},
year = {2025},
isbn = {9798400712760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696630.3727255},
doi = {10.1145/3696630.3727255},
abstract = {The software development life cycle (SDLC) is vital for ensuring the quality of software systems. However, learning SDLC concepts presents unique challenges, such as the need for effective collaboration, real-time interaction, and access to diverse skill sets represented in software development teams. To address these problems, we present DevCoach, a generative AI powered multi-agent system designed to support students learning the SDLC. DevCoach allows students to interact with generative AI agents simulating the different roles in the software development team, engaging in tasks across different phases of SDLC. Through a user study (n = 20), we evaluate the system's effectiveness in enhancing learning, impact on SDLC deliverables, and support for Community of Inquiry (CoI) elements necessary for effective and supportive learning environments. Our results reveal that students using DevCoach achieved significantly higher learning gains and improved task completion rates across all SDLC phases. The system also supports CoI elements, particularly perceived social presence. Participants also lauded the immediate context-aware feedback, interactive learning environment, and diverse expertise provided by the roles within the multi-agent team. These findings demonstrate the potential of generative AI to enhance software engineering education by making it more effective, engaging, and interactive, providing students with collaborative and practical learning experiences.},
booktitle = {Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
pages = {987‚Äì998},
numpages = {12},
keywords = {software development life cycle, generative AI, multi-agent system},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {FSE Companion '25}
}

@inproceedings{10.1145/3709025.3712216,
author = {Gray, Morgan and Zhang, Li and Ashley, Kevin D.},
title = {Generating Case-Based Legal Arguments with LLMs},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712216},
doi = {10.1145/3709025.3712216},
abstract = {Over its decades long history, the field of AI and Law has made significant progress developing and researching formal models of case based reasoning that are capable of producing legal arguments. These models employ argument schemes to replicate legal argumentation. Although their arguments are accurate and explainable, these systems are costly to produce and maintain, requiring manual case representations and expert-crafted algorithms that mimic argument. To address these limitations we employ a prompt-engineering strategy that leads state-of-the-art LLMs to follow argument schemes. We show that it is feasible for LLMs to produce basic case-based legal arguments.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {160‚Äì168},
numpages = {9},
keywords = {Argument Scheme, Factors, Large Language Models, Legal Arguments, Legal Reasoning},
location = {Munich, Germany},
series = {CSLAW '25}
}

@proceedings{10.1145/3678392,
title = {ICFET '24: Proceedings of the 2024 10th International Conference on Frontiers of Educational Technologies},
year = {2024},
isbn = {9798400717123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Malacca, Malaysia}
}

@inproceedings{10.1145/3715928.3737481,
author = {Ashkinaze, Joshua and Mendelsohn, Julia and Qiwei, Li and Budak, Ceren and Gilbert, Eric},
title = {How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment},
year = {2025},
isbn = {9798400714894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715928.3737481},
doi = {10.1145/3715928.3737481},
abstract = {Exposure to large language model output is rapidly increasing. How will seeing AI-generated ideas affect human ideas? We conducted a dynamic experiment (800+ participants, 40+ countries) where participants viewed creative ideas that were from ChatGPT or prior experimental participants, and then brainstormed their own idea. We varied the number of AI-generated examples (none, low, or high exposure) and if the examples were labeled as ‚ÄúAI‚Äù (disclosure). We find that high AI exposure (but not low AI exposure) did not affect the creativity of individual ideas but did increase the average amount and rate of change of collective idea diversity. AI made ideas different, not better. There were no main effects of disclosure. We also found that self-reported creative people were less influenced by knowing an idea was from AI and that participants may knowingly adopt AI ideas when the task is difficult. Our findings suggest that introducing AI ideas may increase collective diversity but not individual creativity.},
booktitle = {Proceedings of the ACM Collective Intelligence Conference},
pages = {198‚Äì213},
numpages = {16},
keywords = {artificial intelligence, large language models, human-computer interaction, creativity, collective intelligence, cultural evolution},
location = {
},
series = {CI '25}
}

@inproceedings{10.1145/3623809.3623820,
author = {de Rooij, Alwin and van den Broek, Simone and Bouw, Michelle and de Wit, Jan},
title = {Co-Designing with a Social Robot Facilitator: Effects of Robot Mood Expression on Human Group Dynamics},
year = {2023},
isbn = {9798400708244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623809.3623820},
doi = {10.1145/3623809.3623820},
abstract = {Social robots can be designed to support the facilitation of co-design sessions. Facilitators regulate group dynamics to promote effective collaboration among stakeholders. Group dynamics are sensitive to mood expressions: Positive mood expressions by the facilitator promote cooperation in the group, whereas negative expressions promote conflict. However, whether mood expressions by a social robot facilitator also influence human group dynamics is an open scientific and practical question. To learn more, an experiment (N = 98) was conducted where small groups engaged in a co-design session led by a social robot facilitator. The robot displayed positive, neutral, or negative mood expressions throughout the session. The results showed that positive robot expressions, compared to neutral or negative expressions, increased perceived robot valence. Perceived robot valence increased cooperation and decreased conflict in the human groups. These findings contribute novel insight into how social robots can be used to innovate how co-design is facilitated.},
booktitle = {Proceedings of the 11th International Conference on Human-Agent Interaction},
pages = {22‚Äì29},
numpages = {8},
keywords = {Affective Computing, Co-Design, Facilitation, Group Dynamics, Human-Agent Interaction, Mood, Social Robotics},
location = {Gothenburg, Sweden},
series = {HAI '23}
}

@inproceedings{10.1145/3632776.3632827,
author = {LC, RAY and Tang, Yuying},
title = {Speculative Design with Generative AI: Applying Stable Diffusion and ChatGPT to imagining climate change futures},
year = {2024},
isbn = {9798400708725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632776.3632827},
doi = {10.1145/3632776.3632827},
abstract = {Policy mandates in addressing climate change are hindered by a lack of intrinsic motivation amongst participants to take collective action. Instead of overt persuasion, this study applied generative AI tools to speculative imagining of future climate scenarios and their adaptation strategies, using a workshop to encourage participants to align themselves with climate action. Participants used text-to-image tools to generate visions of the future in speculative scenarios, then prompted ChatGPT for potential solutions in these scenarios. They then asked text-to-image again to visualize the ChatGPT suggestions. Participants encountered difficulties editing or removing visual elements, dealt with the lack of transparency in the generation process by specifying the physical layout as opposed to the semantics, and collaboratively developed linguistic strategies for visual depiction of novel artifacts. This work shows how generative tools can be used to prototype future scenarios and envision designs that serve social purposes.},
booktitle = {Proceedings of the 11th International Conference on Digital and Interactive Arts},
articleno = {36},
numpages = {8},
keywords = {ChatGPT, Stable diffusion, climate change, co-design workshop, prompt design, speculative design},
location = {Faro, Portugal},
series = {ARTECH '23}
}

@inproceedings{10.1145/3641519.3657407,
author = {Guo, Xun and Zheng, Mingwu and Hou, Liang and Gao, Yuan and Deng, Yufan and Wan, Pengfei and Zhang, Di and Liu, Yufan and Hu, Weiming and Zha, Zhengjun and Huang, Haibin and Ma, Chongyang},
title = {I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657407},
doi = {10.1145/3641519.3657407},
abstract = {Text-guided image-to-video (I2V) generation aims to generate a coherent video that preserves the identity of the input image and semantically aligns with the input prompt. Existing methods typically augment pretrained text-to-video (T2V) models by either concatenating the image with noised video frames channel-wise before being fed into the model or injecting the image embedding produced by pretrained image encoders in cross-attention modules. However, the former approach often necessitates altering the fundamental weights of pretrained T2V models, thus restricting the model‚Äôs compatibility within the open-source communities and disrupting the model‚Äôs prior knowledge. Meanwhile, the latter typically fails to preserve the identity of the input image. We present I2V-Adapter to overcome such limitations. I2V-Adapter adeptly propagates the unnoised input image to subsequent noised frames through a cross-frame attention mechanism, maintaining the identity of the input image without any changes to the pretrained T2V model. Notably, I2V-Adapter only introduces a few trainable parameters, significantly alleviating the training cost and also ensures compatibility with existing community-driven personalized models and control tools. Moreover, we propose a novel Frame Similarity Prior to balance the motion amplitude and the stability of generated videos through two adjustable control coefficients. Our experimental results demonstrate that I2V-Adapter is capable of producing high-quality videos. This performance, coupled with its agility and adaptability, represents a substantial advancement in the field of I2V, particularly for personalized and controllable applications.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {112},
numpages = {12},
keywords = {Diffusion models., Image-to-video generation},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3706598.3713470,
author = {Schneiders, Eike and Seabrooke, Tina and Krook, Joshua and Hyde, Richard and Leesakul, Natalie and Clos, Jeremie and Fischer, Joel E},
title = {Objection Overruled! Lay People can Distinguish Large Language Models from Lawyers, but still Favour Advice from an LLM},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713470},
doi = {10.1145/3706598.3713470},
abstract = {Large Language Models (LLMs) are seemingly infiltrating every domain, and the legal context is no exception. In this paper, we present the results of three experiments (total N&nbsp;=&nbsp;288) that investigated lay people‚Äôs willingness to act upon, and their ability to discriminate between, LLM- and lawyer-generated legal advice. In Experiment 1, participants judged their willingness to act on legal advice when the source of the advice was either known or unknown. When the advice source was unknown, participants indicated that they were significantly more willing to act on the LLM-generated advice. The result of the source unknown condition was replicated in Experiment 2. Intriguingly, despite participants indicating higher willingness to act on LLM-generated advice in Experiments 1 and 2, participants discriminated between the LLM- and lawyer-generated texts significantly above chance-level in Experiment 3. Lastly, we discuss potential explanations and risks of our findings, limitations and future work.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1201},
numpages = {14},
keywords = {Large language model, LLM, legal advice, generative AI, ChatGPT},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713216,
author = {Lee, Heejae and Dominguez Partida, Gabriel and Bowman, Nicholas David and Chauveau, Philippe de Villemor},
title = {Translation and Validation of The Video Game Demand Scale to Spanish},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713216},
doi = {10.1145/3706598.3713216},
abstract = {With efforts to investigate the role of interactivity on user psychology in video games, scholars have demonstrated that interactivity may induce cognitive, emotional, physical (controller and exertional), and social demands of global gamers. However, existing studies are missing Latin American gamers as critical yet understudied gaming communities. Drawing on the interactivity-as-demand model, we conducted a mixed-method online survey to test measurement validity on localized versions of the video game demand scale (VGDS) for Spanish-speaking gamers (N = 195). Results showed that the Spanish-translated scale replicated the a priori five-factor structure of VGDS. Emergent themes from gamers‚Äô comments mirrored VGDS factors, with additional insights into the cognitive demand of creative thinking, emotional demand of feeling nostalgia, physical demand of being precise, and social demand of interacting with non-player characters. These findings provide a pancultural perspective of Spanish-speaking gamers‚Äô perceptions of their gaming while offering nuanced insights into their experiences for future research.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {339},
numpages = {14},
keywords = {Mexico, Spanish, interactivity-as-demand, measurement validity, player psychology, video game demand scale},
location = {
},
series = {CHI '25}
}

@article{10.1145/3663485,
author = {Morales-Garc\'{\i}a, Juan and Llanes, Antonio and Arcas-T\'{u}nez, Francisco and Terroso-S\'{a}enz, Fernando},
title = {Developing Time Series Forecasting Models with Generative Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3663485},
doi = {10.1145/3663485},
abstract = {Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their ability as generators of functional source code for software projects. Nevertheless, their potential as assistants to write the code needed to generate and model Machine Learning (ML) or Deep Learning (DL) architectures has not been fully explored to date. For this reason, this work focuses on evaluating the extent to which different tools based on GLLMs, such as ChatGPT or Copilot, are able to correctly define the source code necessary to generate viable predictive models. The use case defined is the forecasting of a time series that reports the indoor temperature of a greenhouse. The results indicate that, while it is possible to achieve good accuracy metrics with simple predictive models generated by GLLMs, the composition of predictive models with complex architectures using GLLMs is still far from improving the accuracy of predictive models generated by human data scientists.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Deep Learning, Generative Large Language Models (GLLMs), ChatGPT, Copilot, Time series forecasting}
}

@inproceedings{10.1145/3670653.3670680,
author = {Schott, Kevin and Papenmeier, Andrea and Hienert, Daniel and Kern, Dagmar},
title = {What Did I Say Again? Relating User Needs to Search Outcomes in Conversational Commerce},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3670680},
doi = {10.1145/3670653.3670680},
abstract = {Recent advances in natural language processing and deep learning have accelerated the development of digital assistants. In conversational commerce, these assistants help customers find suitable products in online shops through natural language conversations. During the dialogue, the assistant identifies the customer‚Äôs needs and preferences and subsequently suggests potentially relevant products. Traditional online shops often allow users to filter search results based on their preferences using facets. Selected facets can also serve as a reminder of how the product base was filtered. In conversational commerce, however, the absence of facets and the use of advanced natural language processing techniques can leave customers uncertain about how their input was processed by the system. This can hinder transparency and trust, which are critical factors influencing customers‚Äô purchase intentions. To address this issue, we propose a novel text-based digital assistant that, in the product assessment step, explains how specific product aspects relate to the user‚Äôs previous utterances to enhance transparency and facilitate informed decision-making. We conducted a user study (N=135) and found a significant increase in user-perceived transparency when natural language explanations and highlighted text passages were provided, demonstrating their potential to extend system transparency to the product assessment step in conversational commerce.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {129‚Äì139},
numpages = {11},
keywords = {Chatbot, Conversational Commerce, Conversational Search, Conversational User Interfaces, Explanations, Product Search},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3702038.3702071,
author = {da Rosa, Diego Moreira and Guedes, Leandro Soares and Landoni, Monica and Silveira, Milene},
title = {Investigating technology users' behavior and difficulties in two different multilingual contexts},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702071},
doi = {10.1145/3702038.3702071},
abstract = {The popularization of computing devices and internet access, especially in developing countries, has driven attention to an increasing number of software users with varied cultural and linguistic backgrounds. Human-Computer Interaction (HCI) research has thus far considered language communities as static and isolated entities, generally associating them with a specific country. Linguists know, however, that cultures interact and exchange ideas, languages spread across state borders, and individuals often speak two or more languages. For an effective HCI design, developers should consider these social and individual aspects of multilingualism. In this study, we aim to investigate technology users‚Äô behavior and difficulties in different multilingual contexts. An online survey has been conducted with multilingual participants from two universities: one in Switzerland and the other in Brazil. Analysis of 196 valid responses confirms a high level of multilingualism in general, but higher among participants in Switzerland. The types of tasks and the language-related issues reported by the participants varied between the two contexts, indicating that the level of multilingualism impacts users‚Äô behavior online. A final discussion summarizes challenges and opportunities for future studies aiming to propose HCI design approaches with a focus on multilingualism.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {33},
numpages = {12},
keywords = {Human-Computer Interaction, HCI Design, Culture, Multilingual, Multilingualism},
location = {
},
series = {IHC '24}
}

@inproceedings{10.1145/3631991.3631999,
author = {Asadi, Amir Reza},
title = {LLMs in Design Thinking: Autoethnographic Insights and Design Implications},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631991.3631999},
doi = {10.1145/3631991.3631999},
abstract = {This article presents an autoethnographic exploration of the use of Large Language Models (LLMs) in the context of design thinking. Through personal narratives and reflections, the author examines his experiences integrating LLMs as tools to support and enhance the design thinking process. The article discusses the benefits, challenges, and transformative potential of ChatGPT and Google Bard in facilitating ideation, prototyping, and user-centered design. Drawing on personal anecdotes and observations, the author offers insights into the impact of LLMs on idea generation, problem-solving, and collaboration within the design thinking framework. This autoethnographic approach provides a unique perspective on the integration of LLMs in design thinking, shedding light on their potentials as tools for innovation and fostering the insights of their implications for design practitioners and UX researchers. These insights were also used to develop design implications for designing interactions for LLMs, including the concept of Dynamic LLM Enabled Documents.},
booktitle = {Proceedings of the 2023 5th World Symposium on Software Engineering},
pages = {55‚Äì60},
numpages = {6},
keywords = {Autoethnography, Design Thinking, LLMs, User Experience Research},
location = {Tokyo, Japan},
series = {WSSE '23}
}

@inproceedings{10.1145/3656650.3656671,
author = {Barricelli, Barbara Rita and Fogli, Daniela and Gargioni, Luigi and Locoro, Angela and Valtolina, Stefano},
title = {Towards the Unification of Computational Thinking and EUDability: Two Cases from Healthcare},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656671},
doi = {10.1145/3656650.3656671},
abstract = {This paper presents a study about the mapping of the EUDability of End-User Development (EUD) tools with the Computational Thinking (CT) skills of users. This mapping provides an approach to evaluate the suitability of a EUD environment in supporting people performing their daily work while managing and exploiting EUD tools. EUDability is a construct encompassing different dimensions that need to be assessed through a careful scrutiny by human-computer interaction experts, while CT skills should mirror those dimensions from the point of view of assessing the level of ability of users in managing problems with a computational thinking attitude. Moving from the healthcare domain, we present two cases: a tool for geriatric professionals supporting them in the preparation of cognitive exercises for elderly patients; and a tool for pharmacists, which empowers them to create robot programs related to the preparation of personalized medications. These cases have been exploited to show how to unify the EUDability assessment with the CT skills assessment. In particular, the application of the EUDability evaluation method for each tool, as well as the administration of the Computational Thinking Scale to domain experts are shown. The results of the two assessments are reported and discussed, together with the limitations of the present study. The results show the goodness of fit of the proposed EUD tools in the healthcare domain.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {48},
numpages = {9},
keywords = {Computational Thinking, End-User Development, Evaluation, Healthcare},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3658619.3658627,
author = {Kharrufa, Ahmed and Johnson, Ian},
title = {The Potential and Implications of Generative AI on HCI Education},
year = {2024},
isbn = {9798400716591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658619.3658627},
doi = {10.1145/3658619.3658627},
abstract = {Generative AI (GAI) is impacting teaching and learning directly or indirectly across a range of subjects and disciplines. As educators, we need to understand the potential and limitations of AI in HCI education and ensure our graduating HCI students are aware of the potential and limitations of AI in HCI. In this paper, we report on the main pedagogical insights gained from the inclusion of generative AI into a 10-week undergraduate module. We designed the module to encourage student experimentation with GAI models as part of the design brief requirement and planned practical sessions and discussions. Our insights are based on replies to a survey sent out to the students after completing the module. Our key findings, for HCI educators, report on the use of AI as a persona for developing project ideas and creating resources for design, and AI as a mirror for reflecting students‚Äô understanding of key concepts and ideas and highlighting knowledge gaps. We also discuss potential pitfalls that should be considered and the need to assess students‚Äô literacies and assumptions of GAIs as pedagogical tools. Finally, we put forward the case for educators to take the opportunities GAI presents as an educational tool and be experimental, creative, and courageous in their practice. We end with a discussion of our findings in relation to the TPACK framework in HCI.},
booktitle = {Proceedings of the 6th Annual Symposium on HCI Education},
articleno = {10},
numpages = {8},
keywords = {GAI, Gen AI, Generative AI, HCI Education, Pedagogy, TPACK},
location = {New York, NY, USA},
series = {EduCHI '24}
}

@inproceedings{10.1145/3664647.3681433,
author = {Wang, Wenxuan and Bai, Haonan and Huang, Jen-tse and Wan, Yuxuan and Yuan, Youliang and Qiu, Haoyi and Peng, Nanyun and Lyu, Michael},
title = {New Job, New Gender? Measuring the Social Bias in Image Generation Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681433},
doi = {10.1145/3664647.3681433},
abstract = {Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on the significant changes related to gender, race, and age. BiasPainter adopts a key insight that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models. We use BiasPainter to evaluate six widely-used image generation models, such as stable diffusion and Midjourney. Experimental results show that BiasPainter can successfully trigger social bias in image generation models. According to our human evaluation, BiasPainter can achieve 90.8\% accuracy on automatic bias detection, which is significantly higher than the results reported in previous work.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3781‚Äì3789},
numpages = {9},
keywords = {image generation models, model evaluation, social bias},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3641237.3691651,
author = {Kessler, Molly},
title = {Exploring Divergent Healthcare Practices and Emerging Technologies: A Focus on DIY Fecal Microbiota Transplants},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691651},
doi = {10.1145/3641237.3691651},
abstract = {This project examines do-it-yourself (DIY) fecal microbiota transplants (FMT) through the lens of tactical technical communication and rhetoric of health and medicine. While research on microbiome-related interventions like FMT is nascent, patient communities are eager for additional treatment options, leading to the proliferation of online user-generated instructional artifacts for attempting DIY FMT without medical assistance or FDA approval. Simultaneously, generative AI is transforming the information ecologies in which patients engage with medical information and pursue health-related behaviors that align or diverge from approved practices. This project investigates these divergent healthcare practices enabled by user- and AI-generated content.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {52‚Äì59},
numpages = {8},
keywords = {desire lines, divergent pathographies, rhetoric of health and medicine, tactical technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3544549.3585782,
author = {Chan, Samantha and Zhang, Haimo and Nanayakkara, Suranga},
title = {Eye Movement Analysis of Human Visual Recognition Processes with Camera Eye Tracker: Higher Mean and Variance of Fixation Duration for Familiar Images},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585782},
doi = {10.1145/3544549.3585782},
abstract = {Eye movements could provide information on a person‚Äôs cognitive context. Previous works showed that human visual recognition processes could be detected via electrooculography (EOG) data and revealed top-ranked eye movement features for detection. However, they lack analysis on how eye movements differ when viewing recognised (familiar) and unrecognised (unfamiliar) images. EOG methods are less prevalent and have limited scalability for detecting other cognitive processes. Our study with 34 participants showed that saccade count and fixation count decreased while the mean and variance of fixation duration increased with image familiarity. We discuss the differences in eye movements when seeing images of different categories and lessons learnt for our next steps to enable implicit interactions using wearable camera-based eye trackers.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {132},
numpages = {8},
keywords = {Cognitive Context, Eye Movement Analysis, Eye Tracking, Image Familiarity, Physiological Sensing, Visual Memory Recall, Visual Recognition},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3706599.3716217,
author = {Toups Dugas, Phoebe O. and Seetharaman, Bhavani and Fleming, Rebecca J. and Liang, Shano and Elvitigala, Don Samitha and Rode, Jennifer A. and LaLone, Nicolas},
title = {Mobile Maps Continue to Fail Pedestrians: Synthesised Reflective Auto-Aggro-Ethnographies of Walking},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3716217},
doi = {10.1145/3706599.3716217},
abstract = {We consider mobile maps, the everyday smart-device-based programs that locate the user, provide insights into local space, and support wayfinding ‚Äì or do they? The authors collectively reflect on past infuriating experiences with failures of mobile maps as pedestrians. We synthesise these thick descriptions, what we call reflective auto-aggro-ethnographies, to identify shortcomings in mobile maps: hidden verticality, missing local detail, incorrect sensor data, and poor pathing. We turn to human-centred design to point out how these shortcomings should be (or, rather, should have been) addressed.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {638},
numpages = {12},
keywords = {Map interfaces, pedestrians, mobile, GPS, seamful design},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3702038.3702060,
author = {Zaina, Luciana and Prates, Raquel Oliveira and Delabrida Silva, Saul Emanuel and Choma, Joelma and Valentim, Natasha Malveira Costa and Frigo, Luciana Bolan and Bicho, Alessandro de Lima},
title = {GranDIHC-BR 2025-2035 - GC7: Interaction with Emerging Technologies: An Ecosystem Integrating Humans Technologies and Contexts‚ú±},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702060},
doi = {10.1145/3702038.3702060},
abstract = {This article discusses the grand challenge of Emerging Technologies, which is part of the seven Grand Challenges of the Human-Computer Interaction (HCI) community for the years 2025-2035 in Brazil. Emerging technologies are characterized by significant scientific advances and rapid adoption, such as the Internet of Things (IoT), 5G, Big Data, Analytics, Artificial Intelligence (AI), Robotics, and Virtual/Augmented/Mixed Reality (VR/AR/MR). Alongside the development of these technologies, various applications are emerging from a symbiosis among individuals, technologies, and contexts that make up a complex ecosystem. The emerging use of these technologies by human beings reveals specific demands for interaction in this ecosystem, highlighting the relevance of this topic. From an HCI perspective, this article discusses how the Brazilian scientific community should contribute over the next decade to effectively adopt emerging technologies and/or the emerging use of technologies in different contexts. Throughout the text, the identified issues pertinent to this challenge are analyzed from the perspective of how the elements of the ecosystem interact, contextualizing them at a national and global level. An agenda of six research topics is presented, actions to overcome the challenge are discussed, and the expected results for each are listed. Finally, ethical issues regarding research with emerging technologies are highlighted, and a final discussion regarding the other six challenges that are part of the HCI Grand Challenges is presented.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {23},
numpages = {21},
keywords = {emerging technologies, spacial computing, human-computer integration, immersive interaction, human-centered computing, extended reality.},
location = {
},
series = {IHC '24}
}

@inproceedings{10.1145/3729176.3729180,
author = {Kobiella, Charlotte and Mitrevska, Teodora and Schmidt, Albrecht and Draxler, Fiona},
title = {When Efficiency Meets Fulfillment: Understanding Long-Term LLM Integration in Knowledge Work},
year = {2025},
isbn = {9798400713842},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729176.3729180},
doi = {10.1145/3729176.3729180},
abstract = {Large Language Models (LLMs) are transforming knowledge work across industries. While current HCI research emphasizes productivity, users‚Äô subjective experience of integrating LLMs into daily work has received less attention. We conducted a follow-up study of our 2023 investigation by employing a two-week diary study with 15 participants, exploring how prolonged LLM use shapes perceived productivity, accomplishment, and self-efficacy as psychological dimensions of work. Our findings reveal higher ratings of perceived accomplishment with prolonged LLM use. Efficiency emerged as a main driver not only for productivity but also for enhancing users‚Äô sense of accomplishment and self-efficacy, suggesting that thoughtful LLM integration can create more meaningful work experiences. Our research advances our understanding of technology adoption and adaptation, providing insights for developing tools and processes that honor personal fulfillment while leveraging technological advancement.},
booktitle = {Proceedings of the 4th Annual Symposium on Human-Computer Interaction for Work},
articleno = {12},
numpages = {15},
keywords = {Large Language Models, adoption, adaptation, productivity, self-efficacy, sense of accomplishment},
location = {
},
series = {CHIWORK '25}
}

@inproceedings{10.1145/3637528.3671984,
author = {Gong, Jiahui and Ding, Jingtao and Meng, Fanjin and Chen, Guilong and Chen, Hong and Zhao, Shen and Lu, Haisheng and Li, Yong},
title = {A Population-to-individual Tuning Framework for Adapting Pretrained LM to On-device User Intent Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671984},
doi = {10.1145/3637528.3671984},
abstract = {Mobile devices, especially smartphones, can support rich functions and have developed into indispensable tools in daily life. With the rise of generative AI services, smartphones can potentially transform into personalized assistants, anticipating user needs and scheduling services accordingly. Predicting user intents on smartphones, and reflecting anticipated activities based on past interactions and context, remains a pivotal step towards this vision. Existing research predominantly focuses on specific domains, neglecting the challenge of modeling diverse event sequences across dynamic contexts. Leveraging pre-trained language models (PLMs) offers a promising avenue, yet adapting PLMs to on-device user intent prediction presents significant challenges. To address these challenges, we propose PITuning, a Population-to-Individual Tuning framework. PITuning enhances common pattern extraction through dynamic event-to-intent transition modeling and addresses long-tailed preferences via adaptive unlearning strategies. Experimental results on real-world datasets demonstrate PITuning's superior intent prediction performance, highlighting its ability to capture long-tailed preferences and its practicality for on-device prediction scenarios.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {896‚Äì907},
numpages = {12},
keywords = {device-cloud collaboration, personalization, pretrained language model, user intent},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3677389.3702516,
author = {Yasuda, Kotaro and Aritsugi, Masayoshi and Takeuchi, Yukiko and Shibayama, Akihiro and Mendon\c{c}a, Israel},
title = {Disaster Image Tagging Using Generative AI for Digital Archives},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702516},
doi = {10.1145/3677389.3702516},
abstract = {Disaster digital archives play a crucial role in preserving and disseminating data on various natural disasters. To manage these archives effectively, images need to be tagged appropriately and comprehensively, and machine learning is expected to handle this task efficiently. However, existing machine-learning tagging models fail to extract detailed disaster-related information. This study focuses on extracting disaster-specific tags from images using the latest machine-learning techniques.More specifically, we use generative AI to create descriptions of images and extract tags from these descriptions, allowing for more detailed information retrieval compared to traditional tags. By including prior information that the images are disaster-related in the prompts, we aim to achieve more specialized disaster tagging.Qualitative evaluation results suggest that the proposed method extracts more disaster-related tags than existing tagging models, indicating that it provides effective tags for users searching disaster images. This study applies real-world test cases using images from the 2011 Tohoku Earthquake and the 2016 Kumamoto Earthquake.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {43},
numpages = {11},
keywords = {digital archives, deep learning, image tagging},
location = {Hong Kong, China},
series = {JCDL '24}
}

@inproceedings{10.1145/3706468.3706501,
author = {Scarlatos, Alexander and Baker, Ryan S. and Lan, Andrew},
title = {Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706501},
doi = {10.1145/3706468.3706501},
abstract = {Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLM‚Äôs accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {249‚Äì259},
numpages = {11},
keywords = {Knowledge Components, Knowledge Tracing, Large Language Models, Tutoring dialogues},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641825.3687716,
author = {Christiansen, Frederik Roland and Hollensberg, Linus N\o{}rgaard and Jensen, Niko Bach and Julsgaard, Kristian and Jespersen, Kristian Nyborg and Nikolov, Ivan},
title = {Exploring Presence in Interactions with LLM-Driven NPCs: A Comparative Study of Speech Recognition and Dialogue Options},
year = {2024},
isbn = {9798400705359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641825.3687716},
doi = {10.1145/3641825.3687716},
abstract = {Combining modern technologies like large-language models (LLMs), speech-to-text, and text-to-speech can enhance immersion in virtual reality (VR) environments. However, challenges exist in effectively implementing LLMs and educating users. This paper explores implementing LLM-powered virtual social actors and facilitating user communication. We developed a murder mystery game where users interact with LLM-based non-playable characters (NPCs) through interrogation, clue-gathering, and exploration. Two versions were tested: one using speech recognition and another with traditional dialog boxes. While both provided similar social presence, users felt more immersed with speech recognition but found it overwhelming, while the dialog version was more challenging. Slow NPC response times were a source of frustration, highlighting the need for faster generation or better masking for a seamless experience.},
booktitle = {Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology},
articleno = {6},
numpages = {11},
keywords = {Immersive systems, Large Language Models (LLM), NPC, Presence, Social Actors, Speech Recognition, VR},
location = {Trier, Germany},
series = {VRST '24}
}

@proceedings{10.1145/3716489,
title = {SIGMIS-CPR '25: Proceedings of the 2025 Computers and People Research Conference},
year = {2025},
isbn = {9798400714979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3706370.3727869,
author = {Huang, Jenny and Weber, Christoph Johannes and Rothe, Sylvia},
title = {An AI-driven Music Visualization System for Generating Meaningful Audio-Responsive Visuals in Real-Time},
year = {2025},
isbn = {9798400713910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706370.3727869},
doi = {10.1145/3706370.3727869},
abstract = {Music visualizations are visual representations or interpretations of music that often dynamically respond to audio. They have the potential to enhance the immersive and engaging qualities of music, and can improve accessibility to music experiences for individuals with hearing loss. However, common music visualizers, such as those integrated into media players, often rely on simplistic algorithms that only react to instantaneous changes in the audio signal. Consequently, these systems tend to produce repetitive visual patterns that fail to encapsulate more complex musical attributes that evolve over time, such as mood and emotion. On the other hand, music visualization concepts from scholars primarily focus on novel data visualization techniques to represent musical information and overlook aesthetic appeal. To address these limitations, we developed an advanced AI-driven system that integrates Music Information Retrieval, Large Language Models, and Image Generation Models to produce meaningful, audio-reactive visualizations from real-time audio input. A study involving hearing, deaf and hard-of-hearing participants (DHH) was conducted to evaluate the system‚Äôs effectiveness in conveying musical emotion and enhancing the music experience. The valence-arousal ratings of visual, audio, and audiovisual stimuli highlighted the subjective nature of music perception, with participants giving varied responses to the same stimuli. Nevertheless, a moderate correlation was observed between the emotional responses to the music and those evoked by the visualizations, with arousal exhibiting a more significant correlation than valence. Furthermore, the combined experience of music and visuals led to greater consensus in participants‚Äô ratings. Survey responses indicated a strong potential for music visualization systems to enhance music experiences. However, opinions among DHH participants were more diverse and generally more moderate compared to hearing participants, emphasizing the need for customization options to better accommodate individual preferences in future developments.},
booktitle = {Proceedings of the 2025 ACM International Conference on Interactive Media Experiences},
pages = {258‚Äì274},
numpages = {17},
keywords = {Music Visualization, Real-Time Image Generation, Accessibility, Musical Emotion, Large Language Models, Audio-Responsiveness, Music Information Retrieval, Music Emotion Recognition},
location = {
},
series = {IMX '25}
}

@proceedings{10.1145/3745238,
title = {DEAI '25: Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
year = {2025},
isbn = {9798400712791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3589335.3651935,
author = {Stanley Jothiraj, Fiona Victoria and Mashhadi, Afra},
title = {Phoenix: A Federated Generative Diffusion Model},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651935},
doi = {10.1145/3589335.3651935},
abstract = {Generative AI has made impressive strides in enabling users to create diverse and realistic visual content such as images, videos, and audio. However, training generative models on large centralized datasets can pose challenges in terms of data privacy, security, and accessibility. Federated learning (FL) is an approach that uses decentralized techniques to collaboratively train a shared deep learning model while retaining the training data on individual edge devices to preserve data privacy. This paper proposes a novel method for training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data sources using FL techniques. Diffusion models, a newly emerging generative model, show promising results in achieving superior quality images than Generative Adversarial Networks (GANs). Our proposed method Phoenix is an unconditional diffusion model that leverages strategies to improve the data diversity of generated samples even when trained on data with statistical heterogeneity or Non-IID (Non-Independent and Identically Distributed) data. We demonstrate how our approach outperforms the default diffusion model in a FL setting. These results indicate that high-quality samples can be generated by maintaining data diversity, preserving privacy, and reducing communication between data sources, offering exciting new possibilities in the field of generative AI.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1568‚Äì1577},
numpages = {10},
keywords = {diffusion models, federated learning, generative ai, heterogeneous data},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3644713.3644797,
author = {Shakib Kotamjani, Sedigheh and Shirinova, Sojida and Fahimirad, Mehrnaz},
title = {Lecturers perceptions of using Artificial Intelligence in Tertiary Education in Uzbekistan},
year = {2024},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644713.3644797},
doi = {10.1145/3644713.3644797},
abstract = {Artificial intelligence (AI) has revolutionized different aspects of society, including higher education. This paper investigates faculty members' perceptions of using artificial intelligence, chatbots, and generative AI in teaching and learning in Uzbeki's higher education contexts. The researchers employed a qualitative study using semi-structured interviews to collect the data. Purposeful sampling was employed to select participants in this study, and the interviews were conducted face-to-face at the university campus. The study's underlying theory is the Unified Theory of Acceptance and Use of Technology (UTAUT) model, including effort expectancy, performance expectancy, social influence, and facilitating conditions, which were employed as a lens to direct the research. The data were transcribed and analyzed using the deductive approach for the thematic analysis. The findings revealed that lecturers have a positive attitude to adopt and use AI for content creation, assessment and feedback, and doing research in their institution. Some instructors may see it as a valuable tool for generating creative content and aiding student learning. In contrast, others may have concerns about its potential to replace human creativity or biases in generated materials. Lecturers also view AI as a technology to achieve accessibility and equity after overcoming the challenges. Findings revealed that some measurements should be taken about the facilitating conditions and the perceived risks of using AI.},
booktitle = {Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
pages = {570‚Äì578},
numpages = {9},
location = {Dubai, United Arab Emirates},
series = {ICFNDS '23}
}

@inproceedings{10.1145/3657054.3657249,
author = {Millan-Vargas, Adrian Osiel and Sandoval-Almazan, Rodrigo and Valle-Cruz, David},
title = {Impact and barriers to AI in the public sector: the case of the State of Mexico},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657249},
doi = {10.1145/3657054.3657249},
abstract = {The use and implementation of Artificial Intelligence (AI) tools for doing repetitive tasks in the public sector is a challenge, particularly in persuading bureaucrats. However, the potential benefits for citizens, such as improved process and services related to tax payments and basic services using machine learning or diffuse logic for decision making or logistic distribution, are significant. This research aims to understand the perceptions of public managers regarding the impact, functions, and barriers of AI in the context of a local government. A survey was conducted among 32 key public managers from the government of the State of Mexico in the central region to assess their perceptions of AI. The findings indicate that there is widespread concern among public administrators regarding high costs, suggesting the critical need to address financial issues to ensure sustainable implementation of AI. In terms of barriers, the results underscore the urgent necessity of addressing fundamental issues such as connectivity, financial resources, and technological capacity to enable effective integration of AI. This study is relevant as it identifies the key aspects of impact, functions, and barriers for the implementation of AI in a local government.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {81‚Äì89},
numpages = {9},
keywords = {artificial intelligence, barriers, digital government, functions, perceptions, public managers, public sector},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

